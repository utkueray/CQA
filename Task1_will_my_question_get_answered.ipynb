{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_Q4ZIKmIsesZ"
   },
   "source": [
    "ENS 491-492- GRADUATION PROJECT TASK 1\n",
    "\n",
    "Will my question get answered? \n",
    "\n",
    "Classification task will be applied on stackexchange AI data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N0Z4hneAszFV"
   },
   "source": [
    "Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "YV5KEmimpD-Y",
    "outputId": "ccbcbcd3-5e77-4c1f-dd53-1dc78486fd73"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: category_encoders in c:\\users\\utku\\anaconda3\\lib\\site-packages (2.1.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (0.10.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (1.2.1)\n",
      "Requirement already satisfied: patsy>=0.4.1 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (0.5.1)\n",
      "Requirement already satisfied: numpy>=1.11.3 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (1.16.4)\n",
      "Requirement already satisfied: pandas>=0.21.1 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (0.24.2)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from category_encoders) (0.23.1)\n",
      "Requirement already satisfied: six in c:\\users\\utku\\anaconda3\\lib\\site-packages (from patsy>=0.4.1->category_encoders) (1.12.0)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\users\\utku\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2019.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from pandas>=0.21.1->category_encoders) (2.8.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (2.0.0)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\utku\\anaconda3\\lib\\site-packages (from scikit-learn>=0.20.0->category_encoders) (0.13.2)\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "!pip install category_encoders\n",
    "from sklearn.metrics import mean_squared_error \n",
    "from sklearn import preprocessing\n",
    "import xml.etree.ElementTree as et\n",
    "import re\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from itertools import product\n",
    "from os.path import join\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OnwVKAeOs3ve"
   },
   "source": [
    "İmporting nltk library for text data cleaning process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "4wg5EhuPsPqN",
    "outputId": "679c87bb-3166-4316-9bad-42b6329cac98"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Utku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Utku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Utku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\Utku\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "!pip install -q wordcloud\n",
    "import wordcloud\n",
    "\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger') \n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import unicodedata\n",
    "import string\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nqo5Dml-tKyP"
   },
   "source": [
    " \n",
    "Data Gathering and Implementation of Data Frame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZNGbKwIzt9Ny"
   },
   "outputs": [],
   "source": [
    "xtree = et.parse('Posts.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqVEUoMyt_By"
   },
   "outputs": [],
   "source": [
    "xroot = xtree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GEL0xWcKumjz"
   },
   "outputs": [],
   "source": [
    "dfCols = [\"Closed Date\", \"Favorite Count\", \"Comment Count\", \"Answer Count\", \"Tags\", \"Title\",\n",
    "          \"Last Activity Date\", \"Owner User ID\", \"Body\", \"View Count\", \"Score\", \"Creation Date\", \"Post Type ID\", \n",
    "          \"ID\", \"Parent ID\", \"Last Edit Date\", \"Last Editor User ID\", \"Accepted Answer ID\"]\n",
    "dfRows = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8Oy4I-63upXz"
   },
   "outputs": [],
   "source": [
    "for node in xroot:\n",
    "    closedDate = node.attrib.get(\"ClosedDate\")\n",
    "    favCount = node.attrib.get(\"FavoriteCount\")\n",
    "    commentCount = node.attrib.get(\"CommentCount\")\n",
    "    ansCount = node.attrib.get(\"AnswerCount\")\n",
    "    tags = node.attrib.get(\"Tags\")\n",
    "    title = node.attrib.get(\"Title\")\n",
    "    lastActDate = node.attrib.get(\"LastActivityDate\")\n",
    "    ownerUserID = node.attrib.get(\"OwnerUserId\")\n",
    "    body = node.attrib.get(\"Body\")\n",
    "    viewCount = node.attrib.get(\"ViewCount\") \n",
    "    score = node.attrib.get(\"Score\") \n",
    "    creationDate = node.attrib.get(\"CreationDate\") \n",
    "    postTypeID = node.attrib.get(\"PostTypeId\") \n",
    "    ID = node.attrib.get(\"Id\") \n",
    "    parentID = node.attrib.get(\"ParentId\") \n",
    "    lastEditDate = node.attrib.get(\"LastEditDate\") \n",
    "    lastEditorUserID = node.attrib.get(\"LastEditorUserId\") \n",
    "    acceptedAnswerID = node.attrib.get(\"AcceptedAnswerID\")\n",
    "    \n",
    "    dfRows.append({\"Closed Date\": closedDate, \"Favorite Count\": favCount, \"Comment Count\": commentCount,\n",
    "                     \"Answer Count\": ansCount, \"Tags\": tags, \"Title\": title, \"Last Activity Date\": lastActDate,\n",
    "                     \"Owner User ID\": ownerUserID, \"Body\": body, \"View Count\": viewCount, \"Score\": score, \n",
    "                    \"Creation Date\": creationDate, \"Post Type ID\": postTypeID, \"ID\": ID, \"Parent ID\": parentID,\n",
    "                    \"Last Edit Date\": lastEditDate, \"Last Editor User ID\": lastEditorUserID, \"Accepted Answer ID\": acceptedAnswerID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "edNRGz8HurqT"
   },
   "outputs": [],
   "source": [
    "out = pd.DataFrame(dfRows, columns=dfCols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bOIxhhiivNCr"
   },
   "outputs": [],
   "source": [
    "out = out.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "11P5KPvEto8i"
   },
   "source": [
    "Changing the data types of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zjb5IPinvPz7"
   },
   "outputs": [],
   "source": [
    "out['Creation Date'] = pd.to_datetime(out['Creation Date'])\n",
    "out['Last Activity Date'] = pd.to_datetime(out['Last Activity Date'])\n",
    "out['Last Edit Date'] = pd.to_datetime(out['Last Edit Date'])\n",
    "out['Comment Count'] = out['Comment Count'].astype(int)\n",
    "out['Owner User ID'] = out['Owner User ID'].astype(int)\n",
    "out['Post Type ID'] = out['Post Type ID'].astype(int)\n",
    "out['Score'] = out['Score'].astype(int)\n",
    "out['Favorite Count'] = out['Favorite Count'].astype(int)\n",
    "out['Answer Count'] = out['Answer Count'].astype(int)\n",
    "out['View Count'] = out['View Count'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "HRnomnsHdAes",
    "outputId": "f319d612-c33f-4c84-9975-71712db7a0d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Closed Date                    object\n",
       "Favorite Count                  int32\n",
       "Comment Count                   int32\n",
       "Answer Count                    int32\n",
       "Tags                           object\n",
       "Title                          object\n",
       "Last Activity Date     datetime64[ns]\n",
       "Owner User ID                   int32\n",
       "Body                           object\n",
       "View Count                      int32\n",
       "Score                           int32\n",
       "Creation Date          datetime64[ns]\n",
       "Post Type ID                    int32\n",
       "ID                             object\n",
       "Parent ID                      object\n",
       "Last Edit Date         datetime64[ns]\n",
       "Last Editor User ID            object\n",
       "Accepted Answer ID              int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3e5SABR2Osa"
   },
   "source": [
    "Categorizing Time Data into Morning/Midday/Evening/Night\n",
    "\n",
    "**According to UTC**\n",
    "\n",
    "05:00-10:00 Morning   -->1     24:00 - 05:00 NY Night\n",
    "\n",
    "11:00 16:00 Midday    -->2     06:00 - 11:00 NY Morning\n",
    "\n",
    "17:00 22:00 Afternoon -->3     12:00 - 17:00 NY Midday\n",
    "\n",
    "23:00 04:00 Night     -->4     18:00 - 23:00 NY Evening"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 340
    },
    "colab_type": "code",
    "id": "ZIiKrJ6XqhQu",
    "outputId": "1f767ee6-fdfe-43e7-8ec2-aaa219a3138a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Answer Count</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Last Activity Date</th>\n",
       "      <th>Owner User ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>View Count</th>\n",
       "      <th>Score</th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Post Type ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Parent ID</th>\n",
       "      <th>Last Edit Date</th>\n",
       "      <th>Last Editor User ID</th>\n",
       "      <th>Accepted Answer ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;backpropagation&gt;&lt;terminology...</td>\n",
       "      <td>What is \"backprop\"?</td>\n",
       "      <td>2019-11-16 17:56:22.093</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;What does \"backprop\" mean? Is the \"backprop...</td>\n",
       "      <td>436</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-11-16 17:56:22.093</td>\n",
       "      <td>2444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;statistica...</td>\n",
       "      <td>How does noise affect generalization?</td>\n",
       "      <td>2019-02-23 22:36:37.133</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;Does increasing the noise in data help to i...</td>\n",
       "      <td>546</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2019-02-23 22:36:19.090</td>\n",
       "      <td>2444</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2016-08-02 15:40:24.820</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;p&gt;\"Backprop\" is the same as \"backpropagation\"...</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1970-01-01 00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;deep-network&gt;&lt;search&gt;&lt;neurons&gt;</td>\n",
       "      <td>How to find the optimal number of neurons per ...</td>\n",
       "      <td>2018-10-18 10:45:15.213</td>\n",
       "      <td>8</td>\n",
       "      <td>&lt;p&gt;When you're writing your algorithm, how do ...</td>\n",
       "      <td>930</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-18 10:45:15.213</td>\n",
       "      <td>10135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016-08-02T16:27:32.070</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;python&gt;&lt;mindstorms&gt;</td>\n",
       "      <td>How to program AI in Mindstorms</td>\n",
       "      <td>2018-10-18 10:44:51.623</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;p&gt;I have a LEGO Mindstorms EV3 and I'm wonder...</td>\n",
       "      <td>2692</td>\n",
       "      <td>-3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-10-18 10:44:51.623</td>\n",
       "      <td>10135</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Closed Date  Favorite Count  Comment Count  Answer Count  \\\n",
       "0                        0               1              0             3   \n",
       "1                        0               1              0             3   \n",
       "2                        0               0              0             0   \n",
       "3                        0              10              0             4   \n",
       "4  2016-08-02T16:27:32.070               0              4             2   \n",
       "\n",
       "                                                Tags  \\\n",
       "0  <neural-networks><backpropagation><terminology...   \n",
       "1  <neural-networks><machine-learning><statistica...   \n",
       "2                                                  0   \n",
       "3                    <deep-network><search><neurons>   \n",
       "4                               <python><mindstorms>   \n",
       "\n",
       "                                               Title      Last Activity Date  \\\n",
       "0                                What is \"backprop\"? 2019-11-16 17:56:22.093   \n",
       "1              How does noise affect generalization? 2019-02-23 22:36:37.133   \n",
       "2                                                  0 2016-08-02 15:40:24.820   \n",
       "3  How to find the optimal number of neurons per ... 2018-10-18 10:45:15.213   \n",
       "4                    How to program AI in Mindstorms 2018-10-18 10:44:51.623   \n",
       "\n",
       "   Owner User ID                                               Body  \\\n",
       "0              8  <p>What does \"backprop\" mean? Is the \"backprop...   \n",
       "1              8  <p>Does increasing the noise in data help to i...   \n",
       "2              4  <p>\"Backprop\" is the same as \"backpropagation\"...   \n",
       "3              8  <p>When you're writing your algorithm, how do ...   \n",
       "4              5  <p>I have a LEGO Mindstorms EV3 and I'm wonder...   \n",
       "\n",
       "   View Count  Score Creation Date  Post Type ID ID Parent ID  \\\n",
       "0         436      8             2             1  1         0   \n",
       "1         546     10             2             1  2         0   \n",
       "2           0     13             2             2  3         1   \n",
       "3         930     29             2             1  4         0   \n",
       "4        2692     -3             2             1  5         0   \n",
       "\n",
       "           Last Edit Date Last Editor User ID  Accepted Answer ID  \n",
       "0 2019-11-16 17:56:22.093                2444                   0  \n",
       "1 2019-02-23 22:36:19.090                2444                   0  \n",
       "2 1970-01-01 00:00:00.000                   0                   0  \n",
       "3 2018-10-18 10:45:15.213               10135                   0  \n",
       "4 2018-10-18 10:44:51.623               10135                   0  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_part_of_day(x):\n",
    "    return (\n",
    "        \"1\" if 5 <= int(x.strftime('%H')) <= 10\n",
    "        else\n",
    "        \"2\" if 11<=  int(x.strftime('%H'))<= 16\n",
    "        else\n",
    "        \"3\" if 17 <= int(x.strftime('%H'))  <= 22\n",
    "        else\n",
    "        \"4\"\n",
    "    )\n",
    "    \n",
    "out[\"Creation Date\"] = out[\"Creation Date\"].apply(get_part_of_day)\n",
    "out.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "E1-ffLojmob_"
   },
   "source": [
    "One Hot Encoding implemented on the date data that had been encoded with label encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a0l-1B1vfm37"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories = \"auto\",sparse = False, drop = \"first\")\n",
    "# One-Hot-Encode Class column of df\n",
    "temp = ohe.fit_transform(out[[\"Creation Date\"]])\n",
    "\n",
    "\n",
    "# Converting into dataframe\n",
    "ohe_column = pd.DataFrame(temp, columns = [\"CreationDate_1\",\"CreationDate_2\",\"CreationDate_3\"])\n",
    "#containating ohe column\n",
    "out= pd.concat([out,ohe_column],axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "D2Gdi1dSqenH"
   },
   "source": [
    "Demonstration of dataframe after one hot encoding applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 278
    },
    "colab_type": "code",
    "id": "vVkGeI_aqSm-",
    "outputId": "0abfc2d9-af9e-4150-9798-3e4ca876b977"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Closed Date</th>\n",
       "      <th>Favorite Count</th>\n",
       "      <th>Comment Count</th>\n",
       "      <th>Answer Count</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Title</th>\n",
       "      <th>Last Activity Date</th>\n",
       "      <th>Owner User ID</th>\n",
       "      <th>Body</th>\n",
       "      <th>View Count</th>\n",
       "      <th>...</th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Post Type ID</th>\n",
       "      <th>ID</th>\n",
       "      <th>Parent ID</th>\n",
       "      <th>Last Edit Date</th>\n",
       "      <th>Last Editor User ID</th>\n",
       "      <th>Accepted Answer ID</th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13816</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-02-29 21:18:06.833</td>\n",
       "      <td>2193</td>\n",
       "      <td>&lt;ol&gt;\\n&lt;li&gt;It's not possible, as in the chain i...</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>18333</td>\n",
       "      <td>18332</td>\n",
       "      <td>2020-02-29 21:18:06.833</td>\n",
       "      <td>2193</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13817</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;convolutional-neural-networks&gt;&lt;object-detection&gt;</td>\n",
       "      <td>How to adapt MTCNN to large images with relati...</td>\n",
       "      <td>2020-02-29 19:20:08.860</td>\n",
       "      <td>16871</td>\n",
       "      <td>&lt;p&gt;This question could be generalised to how t...</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18334</td>\n",
       "      <td>0</td>\n",
       "      <td>1970-01-01 00:00:00.000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13818</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;math&gt;&lt;svm&gt;</td>\n",
       "      <td>What are the variables used in a Gaussian radi...</td>\n",
       "      <td>2020-03-01 02:00:34.490</td>\n",
       "      <td>29877</td>\n",
       "      <td>&lt;p&gt;If I have the Gaussian kernel&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sp...</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>18336</td>\n",
       "      <td>0</td>\n",
       "      <td>2020-03-01 02:00:34.490</td>\n",
       "      <td>2444</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Closed Date  Favorite Count  Comment Count  Answer Count  \\\n",
       "13816           0               0              5             0   \n",
       "13817           0               0              0             0   \n",
       "13818           0               0              0             0   \n",
       "\n",
       "                                                    Tags  \\\n",
       "13816                                                  0   \n",
       "13817  <convolutional-neural-networks><object-detection>   \n",
       "13818                      <machine-learning><math><svm>   \n",
       "\n",
       "                                                   Title  \\\n",
       "13816                                                  0   \n",
       "13817  How to adapt MTCNN to large images with relati...   \n",
       "13818  What are the variables used in a Gaussian radi...   \n",
       "\n",
       "           Last Activity Date  Owner User ID  \\\n",
       "13816 2020-02-29 21:18:06.833           2193   \n",
       "13817 2020-02-29 19:20:08.860          16871   \n",
       "13818 2020-03-01 02:00:34.490          29877   \n",
       "\n",
       "                                                    Body  View Count  ...  \\\n",
       "13816  <ol>\\n<li>It's not possible, as in the chain i...           0  ...   \n",
       "13817  <p>This question could be generalised to how t...           8  ...   \n",
       "13818  <p>If I have the Gaussian kernel</p>\\n\\n<p><sp...           4  ...   \n",
       "\n",
       "       Creation Date Post Type ID     ID Parent ID          Last Edit Date  \\\n",
       "13816              3            2  18333     18332 2020-02-29 21:18:06.833   \n",
       "13817              3            1  18334         0 1970-01-01 00:00:00.000   \n",
       "13818              4            1  18336         0 2020-03-01 02:00:34.490   \n",
       "\n",
       "      Last Editor User ID Accepted Answer ID  CreationDate_1  CreationDate_2  \\\n",
       "13816                2193                  0             0.0             1.0   \n",
       "13817                   0                  0             0.0             1.0   \n",
       "13818                2444                  0             0.0             0.0   \n",
       "\n",
       "       CreationDate_3  \n",
       "13816             0.0  \n",
       "13817             0.0  \n",
       "13818             1.0  \n",
       "\n",
       "[3 rows x 21 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QcBya_l1tuch"
   },
   "source": [
    "Those who has Post Type Id= 1 are questions in this task only questions data will be used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yROOAmyTvc8d"
   },
   "outputs": [],
   "source": [
    "out = out[(out['Post Type ID'] == 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j6eYobU8LUXs"
   },
   "outputs": [],
   "source": [
    "out=out.drop(axis=1,columns=[\"Post Type ID\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qBoT5BPYufat"
   },
   "source": [
    "Since our question is to classify whether the question will get answered , we have labeled data according to it is answered or not by checking answer counts of the questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EfPvReeFpCRI"
   },
   "outputs": [],
   "source": [
    "out['IsAnswered'] = np.where(out['Answer Count']>0, '1', '0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l6kI-ADCu0nI"
   },
   "source": [
    "Tag count is calculated and used as a parameter in dataframe \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZR4TQ-luxgO"
   },
   "outputs": [],
   "source": [
    "out['Tag Count'] = out['Tags'].str.count('<')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_USppyEAh2NH"
   },
   "source": [
    "q (questions abbreviation) data frame consist of the parameters that will be used from Posts.xml data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ejf049slrw_s"
   },
   "outputs": [],
   "source": [
    "q = out[[\"CreationDate_1\",\"CreationDate_2\",\"CreationDate_3\",'Owner User ID','Title','Body','ID','Tags','Tag Count','IsAnswered']]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3Oqffe0ciPRD"
   },
   "source": [
    "10 parameters will be used from Posts.xml data and ID (question id) will be removed later .It was kept in this stage to identify questions ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uzUfU-vlyi66",
    "outputId": "22cb2d45-1179-4981-f47c-61092b8afc5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5805, 10)\n"
     ]
    }
   ],
   "source": [
    "print(q.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "5C0RfRuW5wfT",
    "outputId": "0542b536-8240-4506-f49b-2ea6484c40e9"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>Owner User ID</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>IsAnswered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What is \"backprop\"?</td>\n",
       "      <td>&lt;p&gt;What does \"backprop\" mean? Is the \"backprop...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;backpropagation&gt;&lt;terminology...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>How does noise affect generalization?</td>\n",
       "      <td>&lt;p&gt;Does increasing the noise in data help to i...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;statistica...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>How to find the optimal number of neurons per ...</td>\n",
       "      <td>&lt;p&gt;When you're writing your algorithm, how do ...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;deep-network&gt;&lt;search&gt;&lt;neurons&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>How to program AI in Mindstorms</td>\n",
       "      <td>&lt;p&gt;I have a LEGO Mindstorms EV3 and I'm wonder...</td>\n",
       "      <td>5</td>\n",
       "      <td>&lt;python&gt;&lt;mindstorms&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>Are humans intelligent according to the defini...</td>\n",
       "      <td>&lt;p&gt;Given the following definition of an intell...</td>\n",
       "      <td>6</td>\n",
       "      <td>&lt;philosophy&gt;&lt;definitions&gt;&lt;intelligent-agent&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26</td>\n",
       "      <td>Why does Stephen Hawking say \"Artificial Intel...</td>\n",
       "      <td>&lt;p&gt;This quote by Stephen Hawking has been in h...</td>\n",
       "      <td>7</td>\n",
       "      <td>&lt;intelligent-agent&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What is fuzzy logic?</td>\n",
       "      <td>&lt;p&gt;I'm new to A.I. and I'd like to know in sim...</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;deep-network&gt;&lt;terminology&gt;&lt;fuzzy-logic&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38</td>\n",
       "      <td>Can a single neural network handle recognizing...</td>\n",
       "      <td>&lt;p&gt;In particular, an embedded computer (with l...</td>\n",
       "      <td>13</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;image-recognition&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "      <td>Is the Turing Test, or any of its variants, a ...</td>\n",
       "      <td>&lt;p&gt;The &lt;a href=\"https://en.wikipedia.org/wiki/...</td>\n",
       "      <td>15</td>\n",
       "      <td>&lt;turing-test&gt;&lt;strong-ai&gt;&lt;intelligent-agent&gt;&lt;we...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What is \"early stopping\" in machine learning?</td>\n",
       "      <td>&lt;p&gt;What is &lt;a href=\"https://en.wikipedia.org/w...</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;deep-learning&gt;&lt;definitions&gt;&lt;overfitting&gt;&lt;regu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>What is the concept of the technological singu...</td>\n",
       "      <td>&lt;p&gt;I've heard the idea of the technological si...</td>\n",
       "      <td>17</td>\n",
       "      <td>&lt;philosophy&gt;&lt;definitions&gt;&lt;agi&gt;&lt;superintelligen...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What are the methods of optimizing overfitted ...</td>\n",
       "      <td>&lt;p&gt;I'm worrying that my network has become too...</td>\n",
       "      <td>21</td>\n",
       "      <td>&lt;deep-network&gt;&lt;overfitting&gt;&lt;optimization&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>How could emotional intelligence be implemented?</td>\n",
       "      <td>&lt;p&gt;I've seen emotional intelligence defined as...</td>\n",
       "      <td>26</td>\n",
       "      <td>&lt;turing-test&gt;&lt;emotional-intelligence&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>Is a genetic algorithm an example of artificia...</td>\n",
       "      <td>&lt;p&gt;Since human intelligence presumably is a fu...</td>\n",
       "      <td>28</td>\n",
       "      <td>&lt;philosophy&gt;&lt;genetic-algorithms&gt;&lt;terminology&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>69</td>\n",
       "      <td>What is the difference between artificial inte...</td>\n",
       "      <td>&lt;p&gt;These two terms seem to be related, especia...</td>\n",
       "      <td>35</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;terminology&gt;&lt;comparison&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29</td>\n",
       "      <td>To what extent can quantum computers help to d...</td>\n",
       "      <td>&lt;p&gt;What aspects of quantum computers, if any, ...</td>\n",
       "      <td>36</td>\n",
       "      <td>&lt;quantum-computing&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>What is a Markov chain and how can it be used ...</td>\n",
       "      <td>&lt;p&gt;I believe a Markov chain is a sequence of e...</td>\n",
       "      <td>37</td>\n",
       "      <td>&lt;genetic-algorithms&gt;&lt;markov-chain&gt;&lt;probability&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What is the \"dropout\" technique?</td>\n",
       "      <td>&lt;p&gt;What purpose does the \"dropout\" method serv...</td>\n",
       "      <td>40</td>\n",
       "      <td>&lt;deep-network&gt;&lt;overfitting&gt;&lt;performance&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>72</td>\n",
       "      <td>Can the IQ of an AI program be measured?</td>\n",
       "      <td>&lt;p&gt;Can an AI program have an IQ?&lt;/p&gt;\\n\\n&lt;p&gt;In ...</td>\n",
       "      <td>41</td>\n",
       "      <td>&lt;intelligence-testing&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What is the purpose of the hidden layers?</td>\n",
       "      <td>&lt;p&gt;Why would anybody want to use \"hidden layer...</td>\n",
       "      <td>42</td>\n",
       "      <td>&lt;hidden-layers&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>When did Artificial Intelligence research firs...</td>\n",
       "      <td>&lt;p&gt;When did research into Artificial Intellige...</td>\n",
       "      <td>46</td>\n",
       "      <td>&lt;history&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>How can generalization error be estimated?</td>\n",
       "      <td>&lt;p&gt;How would you estimate the generalisation e...</td>\n",
       "      <td>50</td>\n",
       "      <td>&lt;deep-network&gt;&lt;generalization&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>62</td>\n",
       "      <td>Is it possible to implement reinforcement lear...</td>\n",
       "      <td>&lt;p&gt;I've implemented &lt;a href=\"https://en.wikipe...</td>\n",
       "      <td>52</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;reinforcement-learning&gt;&lt;deep...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>Does the recent advent of a Go playing compute...</td>\n",
       "      <td>&lt;p&gt;I read that in the spring of 2016 a compute...</td>\n",
       "      <td>54</td>\n",
       "      <td>&lt;game-theory&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>Who first coined the term Artificial Intellige...</td>\n",
       "      <td>&lt;p&gt;Who first coined the term Artificial Intell...</td>\n",
       "      <td>58</td>\n",
       "      <td>&lt;terminology&gt;&lt;history&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>77</td>\n",
       "      <td>What are the main problems hindering current A...</td>\n",
       "      <td>&lt;p&gt;I have a background in Computer Engineering...</td>\n",
       "      <td>60</td>\n",
       "      <td>&lt;machine-learning&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What kind of problems require more than 2 hidd...</td>\n",
       "      <td>&lt;p&gt;I've read that the most of the problems can...</td>\n",
       "      <td>63</td>\n",
       "      <td>&lt;deep-network&gt;&lt;hidden-layers&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>55</td>\n",
       "      <td>What were the first areas of research and what...</td>\n",
       "      <td>&lt;p&gt;What were the first areas of research into ...</td>\n",
       "      <td>64</td>\n",
       "      <td>&lt;history&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>What are the real world uses for SAT solvers?</td>\n",
       "      <td>&lt;p&gt;Why somebody would use SAT solvers (&lt;a href...</td>\n",
       "      <td>67</td>\n",
       "      <td>&lt;models&gt;&lt;problem-solving&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>46</td>\n",
       "      <td>What genetic algorithm designs are there that ...</td>\n",
       "      <td>&lt;p&gt;What designs for genetic algorithms are the...</td>\n",
       "      <td>68</td>\n",
       "      <td>&lt;genetic-algorithms&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2844</td>\n",
       "      <td>YOLOv3 Model Structure: Why is filters = (clas...</td>\n",
       "      <td>&lt;p&gt;Here's a tutorial about doing custom traini...</td>\n",
       "      <td>18273</td>\n",
       "      <td>&lt;computer-vision&gt;&lt;yolo&gt;&lt;darknet&gt;&lt;ml-model&gt;&lt;con...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13763</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33850</td>\n",
       "      <td>How is the gradient with respect to weights de...</td>\n",
       "      <td>&lt;p&gt;This is a &lt;a href=\"https://stats.stackexcha...</td>\n",
       "      <td>18276</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;backpropagation&gt;&lt;papers&gt;&lt;re...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13764</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32512</td>\n",
       "      <td>How can I deploy a Keras machine translation m...</td>\n",
       "      <td>&lt;p&gt;I want to deploy a machine translation syst...</td>\n",
       "      <td>18277</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;keras&gt;&lt;machi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13765</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33227</td>\n",
       "      <td>What are the conditions for the convergence of...</td>\n",
       "      <td>&lt;p&gt;Is it correct that for SARSA to converge to...</td>\n",
       "      <td>18278</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;math&gt;&lt;proofs&gt;&lt;converg...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13769</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33227</td>\n",
       "      <td>Does SARSA(0) converge to the optimal policy i...</td>\n",
       "      <td>&lt;p&gt;The conditions of convergence of SARSA(0) t...</td>\n",
       "      <td>18282</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;proofs&gt;&lt;convergence&gt;&lt;...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13770</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33227</td>\n",
       "      <td>Is there an advantage in decaying $\\epsilon$ d...</td>\n",
       "      <td>&lt;p&gt;If the agent is following an &lt;span class=\"m...</td>\n",
       "      <td>18283</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;q-learning&gt;&lt;convergence&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13773</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32694</td>\n",
       "      <td>Why my network overfits on the CIFAR-10 dataset?</td>\n",
       "      <td>&lt;p&gt;I built the following network architecture:...</td>\n",
       "      <td>18286</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;deep-learning&gt;&lt;convolutiona...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13775</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27047</td>\n",
       "      <td>How is the expected value in the loss function...</td>\n",
       "      <td>&lt;p&gt;In &lt;a href=\"https://www.cs.toronto.edu/~vmn...</td>\n",
       "      <td>18288</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;q-learning&gt;&lt;math&gt;&lt;dqn&gt;</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13776</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33862</td>\n",
       "      <td>How should I define the state space for this l...</td>\n",
       "      <td>&lt;p&gt;I would like to ask for a piece of advice w...</td>\n",
       "      <td>18289</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;ai-design&gt;&lt;q-learning...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13777</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1671</td>\n",
       "      <td>How do we define intention if there is no free...</td>\n",
       "      <td>&lt;p&gt;There is an idea that intentionality may be...</td>\n",
       "      <td>18290</td>\n",
       "      <td>&lt;philosophy&gt;&lt;intelligent-agent&gt;&lt;intelligence&gt;&lt;...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13778</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33863</td>\n",
       "      <td>AI Logistic center simulation</td>\n",
       "      <td>&lt;p&gt;&lt;img src=\"https://i.stack.imgur.com/k2fyw.j...</td>\n",
       "      <td>18291</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;ai-design&gt;&lt;tensorflow...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13780</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32750</td>\n",
       "      <td>Is it legal to construct a public image databa...</td>\n",
       "      <td>&lt;p&gt;I am trying to put together a public agricu...</td>\n",
       "      <td>18293</td>\n",
       "      <td>&lt;deep-learning&gt;&lt;convolutional-neural-networks&gt;...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33534</td>\n",
       "      <td>How to create Create and set virtual environme...</td>\n",
       "      <td>&lt;p&gt;I am new in python and pycharm. how i can c...</td>\n",
       "      <td>18296</td>\n",
       "      <td>&lt;python&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13783</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33523</td>\n",
       "      <td>Using ML for Enemy Generation in Video Games</td>\n",
       "      <td>&lt;p&gt;I am attempting to make a 2-D platformer ga...</td>\n",
       "      <td>18297</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;game-ai&gt;&lt;g...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13784</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2844</td>\n",
       "      <td>What are the reasons behind slow YOLO training?</td>\n",
       "      <td>&lt;p&gt;I'm testing out YOLOv3 using the 'darknet' ...</td>\n",
       "      <td>18298</td>\n",
       "      <td>&lt;training&gt;&lt;computer-vision&gt;&lt;object-detection&gt;&lt;...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13785</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33820</td>\n",
       "      <td>Suitable deep learning algorithms for spatial ...</td>\n",
       "      <td>&lt;p&gt;I have a task of classifying spatial data f...</td>\n",
       "      <td>18299</td>\n",
       "      <td>&lt;deep-learning&gt;&lt;geometric-deep-learning&gt;&lt;graph...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13789</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33848</td>\n",
       "      <td>Is a dystopian surveillance state computationa...</td>\n",
       "      <td>&lt;p&gt;This isn't really a conspiracy theory quest...</td>\n",
       "      <td>18303</td>\n",
       "      <td>&lt;social&gt;&lt;computation&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33872</td>\n",
       "      <td>What's the best method to predict/generate sig...</td>\n",
       "      <td>&lt;p&gt;I was wondering what is the best method out...</td>\n",
       "      <td>18306</td>\n",
       "      <td>&lt;deep-learning&gt;&lt;time-series&gt;&lt;sequence-modellin...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13795</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33875</td>\n",
       "      <td>Is the summation of consistent heuristic funct...</td>\n",
       "      <td>&lt;p&gt;Imagine that we have a set of heuristic fun...</td>\n",
       "      <td>18310</td>\n",
       "      <td>&lt;search&gt;&lt;proofs&gt;&lt;heuristics&gt;&lt;admissible-heuris...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13798</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33571</td>\n",
       "      <td>Can an AI use your polyphonic natural sounds t...</td>\n",
       "      <td>&lt;p&gt;I've found this &lt;a href=\"https://github.com...</td>\n",
       "      <td>18313</td>\n",
       "      <td>&lt;python&gt;&lt;speech-synthesis&gt;&lt;speech&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13801</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32751</td>\n",
       "      <td>How do 3 channels affect a network when detect...</td>\n",
       "      <td>&lt;p&gt;Yeah I know, best title ever. Anyway,&lt;/p&gt;\\n...</td>\n",
       "      <td>18317</td>\n",
       "      <td>&lt;convolutional-neural-networks&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13803</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2844</td>\n",
       "      <td>GANs: Should Generator update weights when Dis...</td>\n",
       "      <td>&lt;p&gt;My GANs is like this:&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;li&gt;Trai...</td>\n",
       "      <td>18319</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;generative-adversarial-netw...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13804</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32390</td>\n",
       "      <td>Is reinforcement learning suited for real-time...</td>\n",
       "      <td>&lt;p&gt;From what I have seen, any results involvin...</td>\n",
       "      <td>18320</td>\n",
       "      <td>&lt;reinforcement-learning&gt;&lt;applications&gt;&lt;real-time&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13806</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33901</td>\n",
       "      <td>How to model personalized threshold problem wi...</td>\n",
       "      <td>&lt;p&gt;Assume that I have a candidate selection sy...</td>\n",
       "      <td>18323</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;recommender-system&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13807</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33734</td>\n",
       "      <td>Different results obtained for OneVsOneClassif...</td>\n",
       "      <td>&lt;p&gt;When I fitted a OneVsOneClassifier (or OneV...</td>\n",
       "      <td>18324</td>\n",
       "      <td>&lt;classification&gt;&lt;cross-validation&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13808</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8415</td>\n",
       "      <td>Why gradients are so small in deep learning?</td>\n",
       "      <td>&lt;p&gt;The learning rate in my model is &lt;code&gt;0.00...</td>\n",
       "      <td>18325</td>\n",
       "      <td>&lt;deep-learning&gt;</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13809</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5351</td>\n",
       "      <td>How to do machine translation with no labeled ...</td>\n",
       "      <td>&lt;p&gt;Can it be possible to train a neural networ...</td>\n",
       "      <td>18326</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;datasets&gt;&lt;machine-translation&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13815</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27629</td>\n",
       "      <td>In the Markov chain, how are the directions to...</td>\n",
       "      <td>&lt;p&gt;I'm watching the David Silver series on YT ...</td>\n",
       "      <td>18332</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;reinforcement-learning&gt;&lt;mar...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13817</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16871</td>\n",
       "      <td>How to adapt MTCNN to large images with relati...</td>\n",
       "      <td>&lt;p&gt;This question could be generalised to how t...</td>\n",
       "      <td>18334</td>\n",
       "      <td>&lt;convolutional-neural-networks&gt;&lt;object-detection&gt;</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13818</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29877</td>\n",
       "      <td>What are the variables used in a Gaussian radi...</td>\n",
       "      <td>&lt;p&gt;If I have the Gaussian kernel&lt;/p&gt;\\n\\n&lt;p&gt;&lt;sp...</td>\n",
       "      <td>18336</td>\n",
       "      <td>&lt;machine-learning&gt;&lt;math&gt;&lt;svm&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5805 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       CreationDate_1  CreationDate_2  CreationDate_3  Owner User ID  \\\n",
       "0                 1.0             0.0             0.0              8   \n",
       "1                 1.0             0.0             0.0              8   \n",
       "3                 1.0             0.0             0.0              8   \n",
       "4                 1.0             0.0             0.0              5   \n",
       "5                 1.0             0.0             0.0             29   \n",
       "6                 1.0             0.0             0.0             26   \n",
       "9                 1.0             0.0             0.0              8   \n",
       "12                1.0             0.0             0.0             38   \n",
       "14                1.0             0.0             0.0              9   \n",
       "15                1.0             0.0             0.0              8   \n",
       "16                1.0             0.0             0.0             55   \n",
       "20                1.0             0.0             0.0              8   \n",
       "25                1.0             0.0             0.0             55   \n",
       "27                1.0             0.0             0.0             55   \n",
       "33                1.0             0.0             0.0             69   \n",
       "34                1.0             0.0             0.0             29   \n",
       "35                1.0             0.0             0.0             55   \n",
       "38                1.0             0.0             0.0              8   \n",
       "39                1.0             0.0             0.0             72   \n",
       "40                1.0             0.0             0.0              8   \n",
       "44                1.0             0.0             0.0             55   \n",
       "48                1.0             0.0             0.0              8   \n",
       "50                1.0             0.0             0.0             62   \n",
       "52                1.0             0.0             0.0             55   \n",
       "56                1.0             0.0             0.0             55   \n",
       "57                1.0             0.0             0.0             77   \n",
       "60                1.0             0.0             0.0              8   \n",
       "61                1.0             0.0             0.0             55   \n",
       "64                1.0             0.0             0.0              8   \n",
       "65                1.0             0.0             0.0             46   \n",
       "...               ...             ...             ...            ...   \n",
       "13760             0.0             0.0             0.0           2844   \n",
       "13763             0.0             0.0             0.0          33850   \n",
       "13764             1.0             0.0             0.0          32512   \n",
       "13765             1.0             0.0             0.0          33227   \n",
       "13769             1.0             0.0             0.0          33227   \n",
       "13770             0.0             1.0             0.0          33227   \n",
       "13773             0.0             1.0             0.0          32694   \n",
       "13775             0.0             1.0             0.0          27047   \n",
       "13776             0.0             0.0             1.0          33862   \n",
       "13777             0.0             0.0             1.0           1671   \n",
       "13778             0.0             0.0             1.0          33863   \n",
       "13780             0.0             0.0             1.0          32750   \n",
       "13782             0.0             0.0             1.0          33534   \n",
       "13783             0.0             0.0             1.0          33523   \n",
       "13784             0.0             0.0             1.0           2844   \n",
       "13785             0.0             0.0             0.0          33820   \n",
       "13789             0.0             0.0             0.0          33848   \n",
       "13792             0.0             0.0             0.0          33872   \n",
       "13795             1.0             0.0             0.0          33875   \n",
       "13798             0.0             1.0             0.0          33571   \n",
       "13801             0.0             1.0             0.0          32751   \n",
       "13803             0.0             0.0             1.0           2844   \n",
       "13804             0.0             0.0             1.0          32390   \n",
       "13806             0.0             0.0             0.0          33901   \n",
       "13807             0.0             0.0             0.0          33734   \n",
       "13808             0.0             0.0             0.0           8415   \n",
       "13809             0.0             0.0             0.0           5351   \n",
       "13815             0.0             1.0             0.0          27629   \n",
       "13817             0.0             1.0             0.0          16871   \n",
       "13818             0.0             0.0             1.0          29877   \n",
       "\n",
       "                                                   Title  \\\n",
       "0                                    What is \"backprop\"?   \n",
       "1                  How does noise affect generalization?   \n",
       "3      How to find the optimal number of neurons per ...   \n",
       "4                        How to program AI in Mindstorms   \n",
       "5      Are humans intelligent according to the defini...   \n",
       "6      Why does Stephen Hawking say \"Artificial Intel...   \n",
       "9                                   What is fuzzy logic?   \n",
       "12     Can a single neural network handle recognizing...   \n",
       "14     Is the Turing Test, or any of its variants, a ...   \n",
       "15         What is \"early stopping\" in machine learning?   \n",
       "16     What is the concept of the technological singu...   \n",
       "20     What are the methods of optimizing overfitted ...   \n",
       "25      How could emotional intelligence be implemented?   \n",
       "27     Is a genetic algorithm an example of artificia...   \n",
       "33     What is the difference between artificial inte...   \n",
       "34     To what extent can quantum computers help to d...   \n",
       "35     What is a Markov chain and how can it be used ...   \n",
       "38                      What is the \"dropout\" technique?   \n",
       "39              Can the IQ of an AI program be measured?   \n",
       "40             What is the purpose of the hidden layers?   \n",
       "44     When did Artificial Intelligence research firs...   \n",
       "48            How can generalization error be estimated?   \n",
       "50     Is it possible to implement reinforcement lear...   \n",
       "52     Does the recent advent of a Go playing compute...   \n",
       "56     Who first coined the term Artificial Intellige...   \n",
       "57     What are the main problems hindering current A...   \n",
       "60     What kind of problems require more than 2 hidd...   \n",
       "61     What were the first areas of research and what...   \n",
       "64         What are the real world uses for SAT solvers?   \n",
       "65     What genetic algorithm designs are there that ...   \n",
       "...                                                  ...   \n",
       "13760  YOLOv3 Model Structure: Why is filters = (clas...   \n",
       "13763  How is the gradient with respect to weights de...   \n",
       "13764  How can I deploy a Keras machine translation m...   \n",
       "13765  What are the conditions for the convergence of...   \n",
       "13769  Does SARSA(0) converge to the optimal policy i...   \n",
       "13770  Is there an advantage in decaying $\\epsilon$ d...   \n",
       "13773   Why my network overfits on the CIFAR-10 dataset?   \n",
       "13775  How is the expected value in the loss function...   \n",
       "13776  How should I define the state space for this l...   \n",
       "13777  How do we define intention if there is no free...   \n",
       "13778                      AI Logistic center simulation   \n",
       "13780  Is it legal to construct a public image databa...   \n",
       "13782  How to create Create and set virtual environme...   \n",
       "13783       Using ML for Enemy Generation in Video Games   \n",
       "13784    What are the reasons behind slow YOLO training?   \n",
       "13785  Suitable deep learning algorithms for spatial ...   \n",
       "13789  Is a dystopian surveillance state computationa...   \n",
       "13792  What's the best method to predict/generate sig...   \n",
       "13795  Is the summation of consistent heuristic funct...   \n",
       "13798  Can an AI use your polyphonic natural sounds t...   \n",
       "13801  How do 3 channels affect a network when detect...   \n",
       "13803  GANs: Should Generator update weights when Dis...   \n",
       "13804  Is reinforcement learning suited for real-time...   \n",
       "13806  How to model personalized threshold problem wi...   \n",
       "13807  Different results obtained for OneVsOneClassif...   \n",
       "13808       Why gradients are so small in deep learning?   \n",
       "13809  How to do machine translation with no labeled ...   \n",
       "13815  In the Markov chain, how are the directions to...   \n",
       "13817  How to adapt MTCNN to large images with relati...   \n",
       "13818  What are the variables used in a Gaussian radi...   \n",
       "\n",
       "                                                    Body     ID  \\\n",
       "0      <p>What does \"backprop\" mean? Is the \"backprop...      1   \n",
       "1      <p>Does increasing the noise in data help to i...      2   \n",
       "3      <p>When you're writing your algorithm, how do ...      4   \n",
       "4      <p>I have a LEGO Mindstorms EV3 and I'm wonder...      5   \n",
       "5      <p>Given the following definition of an intell...      6   \n",
       "6      <p>This quote by Stephen Hawking has been in h...      7   \n",
       "9      <p>I'm new to A.I. and I'd like to know in sim...     10   \n",
       "12     <p>In particular, an embedded computer (with l...     13   \n",
       "14     <p>The <a href=\"https://en.wikipedia.org/wiki/...     15   \n",
       "15     <p>What is <a href=\"https://en.wikipedia.org/w...     16   \n",
       "16     <p>I've heard the idea of the technological si...     17   \n",
       "20     <p>I'm worrying that my network has become too...     21   \n",
       "25     <p>I've seen emotional intelligence defined as...     26   \n",
       "27     <p>Since human intelligence presumably is a fu...     28   \n",
       "33     <p>These two terms seem to be related, especia...     35   \n",
       "34     <p>What aspects of quantum computers, if any, ...     36   \n",
       "35     <p>I believe a Markov chain is a sequence of e...     37   \n",
       "38     <p>What purpose does the \"dropout\" method serv...     40   \n",
       "39     <p>Can an AI program have an IQ?</p>\\n\\n<p>In ...     41   \n",
       "40     <p>Why would anybody want to use \"hidden layer...     42   \n",
       "44     <p>When did research into Artificial Intellige...     46   \n",
       "48     <p>How would you estimate the generalisation e...     50   \n",
       "50     <p>I've implemented <a href=\"https://en.wikipe...     52   \n",
       "52     <p>I read that in the spring of 2016 a compute...     54   \n",
       "56     <p>Who first coined the term Artificial Intell...     58   \n",
       "57     <p>I have a background in Computer Engineering...     60   \n",
       "60     <p>I've read that the most of the problems can...     63   \n",
       "61     <p>What were the first areas of research into ...     64   \n",
       "64     <p>Why somebody would use SAT solvers (<a href...     67   \n",
       "65     <p>What designs for genetic algorithms are the...     68   \n",
       "...                                                  ...    ...   \n",
       "13760  <p>Here's a tutorial about doing custom traini...  18273   \n",
       "13763  <p>This is a <a href=\"https://stats.stackexcha...  18276   \n",
       "13764  <p>I want to deploy a machine translation syst...  18277   \n",
       "13765  <p>Is it correct that for SARSA to converge to...  18278   \n",
       "13769  <p>The conditions of convergence of SARSA(0) t...  18282   \n",
       "13770  <p>If the agent is following an <span class=\"m...  18283   \n",
       "13773  <p>I built the following network architecture:...  18286   \n",
       "13775  <p>In <a href=\"https://www.cs.toronto.edu/~vmn...  18288   \n",
       "13776  <p>I would like to ask for a piece of advice w...  18289   \n",
       "13777  <p>There is an idea that intentionality may be...  18290   \n",
       "13778  <p><img src=\"https://i.stack.imgur.com/k2fyw.j...  18291   \n",
       "13780  <p>I am trying to put together a public agricu...  18293   \n",
       "13782  <p>I am new in python and pycharm. how i can c...  18296   \n",
       "13783  <p>I am attempting to make a 2-D platformer ga...  18297   \n",
       "13784  <p>I'm testing out YOLOv3 using the 'darknet' ...  18298   \n",
       "13785  <p>I have a task of classifying spatial data f...  18299   \n",
       "13789  <p>This isn't really a conspiracy theory quest...  18303   \n",
       "13792  <p>I was wondering what is the best method out...  18306   \n",
       "13795  <p>Imagine that we have a set of heuristic fun...  18310   \n",
       "13798  <p>I've found this <a href=\"https://github.com...  18313   \n",
       "13801  <p>Yeah I know, best title ever. Anyway,</p>\\n...  18317   \n",
       "13803  <p>My GANs is like this:</p>\\n\\n<ul>\\n<li>Trai...  18319   \n",
       "13804  <p>From what I have seen, any results involvin...  18320   \n",
       "13806  <p>Assume that I have a candidate selection sy...  18323   \n",
       "13807  <p>When I fitted a OneVsOneClassifier (or OneV...  18324   \n",
       "13808  <p>The learning rate in my model is <code>0.00...  18325   \n",
       "13809  <p>Can it be possible to train a neural networ...  18326   \n",
       "13815  <p>I'm watching the David Silver series on YT ...  18332   \n",
       "13817  <p>This question could be generalised to how t...  18334   \n",
       "13818  <p>If I have the Gaussian kernel</p>\\n\\n<p><sp...  18336   \n",
       "\n",
       "                                                    Tags  Tag Count IsAnswered  \n",
       "0      <neural-networks><backpropagation><terminology...          4          1  \n",
       "1      <neural-networks><machine-learning><statistica...          4          1  \n",
       "3                        <deep-network><search><neurons>          3          1  \n",
       "4                                   <python><mindstorms>          2          1  \n",
       "5           <philosophy><definitions><intelligent-agent>          3          1  \n",
       "6                                    <intelligent-agent>          1          1  \n",
       "9               <deep-network><terminology><fuzzy-logic>          3          1  \n",
       "12                  <neural-networks><image-recognition>          2          1  \n",
       "14     <turing-test><strong-ai><intelligent-agent><we...          4          1  \n",
       "15     <deep-learning><definitions><overfitting><regu...          5          1  \n",
       "16     <philosophy><definitions><agi><superintelligen...          5          1  \n",
       "20             <deep-network><overfitting><optimization>          3          1  \n",
       "25                 <turing-test><emotional-intelligence>          2          1  \n",
       "27         <philosophy><genetic-algorithms><terminology>          3          1  \n",
       "33           <machine-learning><terminology><comparison>          3          1  \n",
       "34                                   <quantum-computing>          1          1  \n",
       "35       <genetic-algorithms><markov-chain><probability>          3          1  \n",
       "38              <deep-network><overfitting><performance>          3          1  \n",
       "39                                <intelligence-testing>          1          1  \n",
       "40                                       <hidden-layers>          1          1  \n",
       "44                                             <history>          1          1  \n",
       "48                        <deep-network><generalization>          2          1  \n",
       "50     <neural-networks><reinforcement-learning><deep...          4          1  \n",
       "52                                         <game-theory>          1          1  \n",
       "56                                <terminology><history>          2          1  \n",
       "57                                    <machine-learning>          1          1  \n",
       "60                         <deep-network><hidden-layers>          2          1  \n",
       "61                                             <history>          1          1  \n",
       "64                             <models><problem-solving>          2          1  \n",
       "65                                  <genetic-algorithms>          1          1  \n",
       "...                                                  ...        ...        ...  \n",
       "13760  <computer-vision><yolo><darknet><ml-model><con...          5          1  \n",
       "13763  <machine-learning><backpropagation><papers><re...          5          0  \n",
       "13764  <machine-learning><deep-learning><keras><machi...          5          0  \n",
       "13765  <reinforcement-learning><math><proofs><converg...          5          1  \n",
       "13769  <reinforcement-learning><proofs><convergence><...          4          0  \n",
       "13770  <reinforcement-learning><q-learning><convergence>          3          1  \n",
       "13773  <machine-learning><deep-learning><convolutiona...          3          0  \n",
       "13775    <reinforcement-learning><q-learning><math><dqn>          4          1  \n",
       "13776  <reinforcement-learning><ai-design><q-learning...          4          0  \n",
       "13777  <philosophy><intelligent-agent><intelligence><...          5          0  \n",
       "13778  <reinforcement-learning><ai-design><tensorflow...          5          0  \n",
       "13780  <deep-learning><convolutional-neural-networks>...          4          0  \n",
       "13782                                           <python>          1          0  \n",
       "13783  <neural-networks><machine-learning><game-ai><g...          5          0  \n",
       "13784  <training><computer-vision><object-detection><...          5          1  \n",
       "13785  <deep-learning><geometric-deep-learning><graph...          4          0  \n",
       "13789                              <social><computation>          2          1  \n",
       "13792  <deep-learning><time-series><sequence-modellin...          5          0  \n",
       "13795  <search><proofs><heuristics><admissible-heuris...          5          1  \n",
       "13798                 <python><speech-synthesis><speech>          3          0  \n",
       "13801                    <convolutional-neural-networks>          1          1  \n",
       "13803  <machine-learning><generative-adversarial-netw...          5          1  \n",
       "13804  <reinforcement-learning><applications><real-time>          3          1  \n",
       "13806             <machine-learning><recommender-system>          2          0  \n",
       "13807                 <classification><cross-validation>          2          0  \n",
       "13808                                    <deep-learning>          1          0  \n",
       "13809  <machine-learning><datasets><machine-translation>          3          1  \n",
       "13815  <machine-learning><reinforcement-learning><mar...          3          1  \n",
       "13817  <convolutional-neural-networks><object-detection>          2          0  \n",
       "13818                      <machine-learning><math><svm>          3          0  \n",
       "\n",
       "[5805 rows x 10 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xv72fBPxi7c_"
   },
   "source": [
    "xml to dict library was used to convert data to data frame, since some failure accured using xml e-tree library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9e7wbgqIpXw2",
    "outputId": "26083939-7c64-4cc2-dc61-7942a526c58d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xmltodict in c:\\users\\utku\\anaconda3\\lib\\site-packages (0.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install xmltodict\n",
    "import xmltodict\n",
    "path = 'Users.xml'\n",
    "xmlDict = xmltodict.parse(et.tostring(et.parse(path).getroot()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D4aRwNPzplTy"
   },
   "outputs": [],
   "source": [
    "a = (list(xmlDict.items())[0])[1]\n",
    "b= (list(a.items())[0])[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mynvf5s4jWGk"
   },
   "source": [
    "This is the initial version of the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "id": "eg6CJUSvpr_U",
    "outputId": "f9a1e9ba-15e4-4c87-d328-49bc7dfcf476"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AboutMe</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>DownVotes</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Location</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>Views</th>\n",
       "      <th>ProfileImageUrl</th>\n",
       "      <th>WebsiteUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Hi, I'm not really a person.&lt;/p&gt;\\n&lt;p&gt;I'm a ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-08-02T00:14:10.580</td>\n",
       "      <td>Community</td>\n",
       "      <td>876</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-08-02T00:14:10.580</td>\n",
       "      <td>on the server farm</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n&lt;p&gt;Developer at Stack Overflow focusing on...</td>\n",
       "      <td>37099</td>\n",
       "      <td>2016-08-02T15:36:45.333</td>\n",
       "      <td>Adam Lear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-05T22:06:40.680</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>https://i.stack.imgur.com/SMEGn.jpg?s=128&amp;g=1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I am the Architecture Lead for Stack Overfl...</td>\n",
       "      <td>7598</td>\n",
       "      <td>2016-08-02T15:36:48.397</td>\n",
       "      <td>Nick Craver</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-11-30T22:09:22.300</td>\n",
       "      <td>Winston-Salem, NC</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>https://i.stack.imgur.com/nGCYr.jpg?s=128&amp;g=1</td>\n",
       "      <td>https://nickcraver.com/blog/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Developer on the Stack Overflow team.  Find...</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-08-02T15:38:01.633</td>\n",
       "      <td>Geoff Dalgas</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-09T03:22:26.573</td>\n",
       "      <td>Corvallis, OR, United States</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>https://i.stack.imgur.com/nDllk.png</td>\n",
       "      <td>http://stackoverflow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://stackexchange.com/users/16...</td>\n",
       "      <td>169656</td>\n",
       "      <td>2016-08-02T15:38:21.100</td>\n",
       "      <td>Franck Dernoncourt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-24T23:40:36.403</td>\n",
       "      <td>Adobe Research, San Jose, CA, USA</td>\n",
       "      <td>1736</td>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>https://i.stack.imgur.com/Z99mk.jpg?s=128&amp;g=1</td>\n",
       "      <td>http://www.francky.me</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             AboutMe AccountId  \\\n",
       "0  <p>Hi, I'm not really a person.</p>\\n<p>I'm a ...        -1   \n",
       "1  \\n\\n<p>Developer at Stack Overflow focusing on...     37099   \n",
       "2  <p>I am the Architecture Lead for Stack Overfl...      7598   \n",
       "3  <p>Developer on the Stack Overflow team.  Find...         2   \n",
       "4  <p><a href=\"https://stackexchange.com/users/16...    169656   \n",
       "\n",
       "              CreationDate         DisplayName DownVotes  Id  \\\n",
       "0  2016-08-02T00:14:10.580           Community       876  -1   \n",
       "1  2016-08-02T15:36:45.333           Adam Lear         0   1   \n",
       "2  2016-08-02T15:36:48.397         Nick Craver         0   2   \n",
       "3  2016-08-02T15:38:01.633        Geoff Dalgas         0   3   \n",
       "4  2016-08-02T15:38:21.100  Franck Dernoncourt         2   4   \n",
       "\n",
       "            LastAccessDate                           Location Reputation  \\\n",
       "0  2016-08-02T00:14:10.580                 on the server farm          1   \n",
       "1  2019-11-05T22:06:40.680                       New York, NY        101   \n",
       "2  2016-11-30T22:09:22.300                  Winston-Salem, NC        101   \n",
       "3  2018-01-09T03:22:26.573       Corvallis, OR, United States        101   \n",
       "4  2020-02-24T23:40:36.403  Adobe Research, San Jose, CA, USA       1736   \n",
       "\n",
       "  UpVotes Views                                ProfileImageUrl  \\\n",
       "0       4     0                                            NaN   \n",
       "1       0   151  https://i.stack.imgur.com/SMEGn.jpg?s=128&g=1   \n",
       "2       0    11  https://i.stack.imgur.com/nGCYr.jpg?s=128&g=1   \n",
       "3       0    12            https://i.stack.imgur.com/nDllk.png   \n",
       "4      15   110  https://i.stack.imgur.com/Z99mk.jpg?s=128&g=1   \n",
       "\n",
       "                     WebsiteUrl  \n",
       "0                           NaN  \n",
       "1                           NaN  \n",
       "2  https://nickcraver.com/blog/  \n",
       "3      http://stackoverflow.com  \n",
       "4         http://www.francky.me  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users= pd.DataFrame.from_dict(b)\n",
    "users.columns = users.columns.str[1:]\n",
    "users.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZERL9MZ9sLT0"
   },
   "source": [
    "Nan Values are filled with \"0\" before any preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "colab_type": "code",
    "id": "LVJfXZV4p2pk",
    "outputId": "7daff78d-cc97-42a4-c59c-c52a74464d1e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AboutMe</th>\n",
       "      <th>AccountId</th>\n",
       "      <th>CreationDate</th>\n",
       "      <th>DisplayName</th>\n",
       "      <th>DownVotes</th>\n",
       "      <th>Id</th>\n",
       "      <th>LastAccessDate</th>\n",
       "      <th>Location</th>\n",
       "      <th>Reputation</th>\n",
       "      <th>UpVotes</th>\n",
       "      <th>Views</th>\n",
       "      <th>ProfileImageUrl</th>\n",
       "      <th>WebsiteUrl</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;p&gt;Hi, I'm not really a person.&lt;/p&gt;\\n&lt;p&gt;I'm a ...</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-08-02T00:14:10.580</td>\n",
       "      <td>Community</td>\n",
       "      <td>876</td>\n",
       "      <td>-1</td>\n",
       "      <td>2016-08-02T00:14:10.580</td>\n",
       "      <td>on the server farm</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\\n\\n&lt;p&gt;Developer at Stack Overflow focusing on...</td>\n",
       "      <td>37099</td>\n",
       "      <td>2016-08-02T15:36:45.333</td>\n",
       "      <td>Adam Lear</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019-11-05T22:06:40.680</td>\n",
       "      <td>New York, NY</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>https://i.stack.imgur.com/SMEGn.jpg?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;p&gt;I am the Architecture Lead for Stack Overfl...</td>\n",
       "      <td>7598</td>\n",
       "      <td>2016-08-02T15:36:48.397</td>\n",
       "      <td>Nick Craver</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-11-30T22:09:22.300</td>\n",
       "      <td>Winston-Salem, NC</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>https://i.stack.imgur.com/nGCYr.jpg?s=128&amp;g=1</td>\n",
       "      <td>https://nickcraver.com/blog/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;p&gt;Developer on the Stack Overflow team.  Find...</td>\n",
       "      <td>2</td>\n",
       "      <td>2016-08-02T15:38:01.633</td>\n",
       "      <td>Geoff Dalgas</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2018-01-09T03:22:26.573</td>\n",
       "      <td>Corvallis, OR, United States</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>https://i.stack.imgur.com/nDllk.png</td>\n",
       "      <td>http://stackoverflow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://stackexchange.com/users/16...</td>\n",
       "      <td>169656</td>\n",
       "      <td>2016-08-02T15:38:21.100</td>\n",
       "      <td>Franck Dernoncourt</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2020-02-24T23:40:36.403</td>\n",
       "      <td>Adobe Research, San Jose, CA, USA</td>\n",
       "      <td>1736</td>\n",
       "      <td>15</td>\n",
       "      <td>110</td>\n",
       "      <td>https://i.stack.imgur.com/Z99mk.jpg?s=128&amp;g=1</td>\n",
       "      <td>http://www.francky.me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>8057826</td>\n",
       "      <td>2016-08-02T15:38:27.643</td>\n",
       "      <td>baranskistad</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2019-07-21T04:30:14.580</td>\n",
       "      <td>Mankato, MN, United States</td>\n",
       "      <td>429</td>\n",
       "      <td>30</td>\n",
       "      <td>19</td>\n",
       "      <td>https://i.stack.imgur.com/Kk1s7.png?s=128&amp;g=1</td>\n",
       "      <td>https://github.com/baranskistad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>3393940</td>\n",
       "      <td>2016-08-02T15:38:27.847</td>\n",
       "      <td>Dom</td>\n",
       "      <td>30</td>\n",
       "      <td>6</td>\n",
       "      <td>2019-09-17T21:30:49.600</td>\n",
       "      <td>Philadelphia, PA</td>\n",
       "      <td>101</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>https://i.stack.imgur.com/B7uhq.png?s=128&amp;g=1</td>\n",
       "      <td>http://None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>6824864</td>\n",
       "      <td>2016-08-02T15:38:28.443</td>\n",
       "      <td>Ben Clayton</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>2019-11-12T11:49:22.170</td>\n",
       "      <td>Plymouth, United Kingdom</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>https://i.stack.imgur.com/4TIdl.jpg?s=128&amp;g=1</td>\n",
       "      <td>http://benclayton.me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>&lt;p&gt;I'm IT engineer programming in anything tha...</td>\n",
       "      <td>22370</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>kenorb</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>0</td>\n",
       "      <td>8543</td>\n",
       "      <td>581</td>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "      <td>http://ads.london</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>&lt;p&gt;Computer Science undergraduate at the Unive...</td>\n",
       "      <td>7263447</td>\n",
       "      <td>2016-08-02T15:38:37.287</td>\n",
       "      <td>Rob Murray</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2018-10-14T10:24:20.607</td>\n",
       "      <td>United Kingdon</td>\n",
       "      <td>461</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>https://i.stack.imgur.com/r4U5R.jpg</td>\n",
       "      <td>https://www.linkedin.com/in/robert-murray-994a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>&lt;p&gt;Staff Writer at Machine Intelligence Resear...</td>\n",
       "      <td>555192</td>\n",
       "      <td>2016-08-02T15:38:37.680</td>\n",
       "      <td>Matthew Graves</td>\n",
       "      <td>25</td>\n",
       "      <td>10</td>\n",
       "      <td>2019-12-02T23:24:15.707</td>\n",
       "      <td>Austin, TX</td>\n",
       "      <td>3919</td>\n",
       "      <td>64</td>\n",
       "      <td>245</td>\n",
       "      <td>https://lh3.googleusercontent.com/-1Y0NrEQiNfE...</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>&lt;p&gt;Duke graduate with BSE in Electrical and Co...</td>\n",
       "      <td>4031433</td>\n",
       "      <td>2016-08-02T15:38:48.693</td>\n",
       "      <td>Abhishek Upadhyaya</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2018-10-02T19:39:01.630</td>\n",
       "      <td>Durham, NC</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>https://i.stack.imgur.com/gAeAy.jpg?s=128&amp;g=1</td>\n",
       "      <td>https://abhishekupadhyaya.github.io/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>&lt;p&gt;Software Engineer&lt;/p&gt;\\n</td>\n",
       "      <td>6064666</td>\n",
       "      <td>2016-08-02T15:38:54.597</td>\n",
       "      <td>Jouramie</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>2016-08-15T15:50:04.147</td>\n",
       "      <td>Québec, QC, Canada</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://lh3.googleusercontent.com/-uY2YHtpTr00...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>&lt;p&gt;I'm a student in shahid maddani high school...</td>\n",
       "      <td>8247602</td>\n",
       "      <td>2016-08-02T15:38:58.930</td>\n",
       "      <td>Taha Akbari</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>2017-01-09T10:34:56.857</td>\n",
       "      <td>Tabriz, East Azerbaijan, Iran</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.gravatar.com/avatar/7ceee8455db052...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>949428</td>\n",
       "      <td>2016-08-02T15:39:06.707</td>\n",
       "      <td>CarrKnight</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>2020-02-25T13:49:59.060</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>&lt;p&gt;&lt;a href=\"https://www.linkedin.com/pulse/eat...</td>\n",
       "      <td>2202424</td>\n",
       "      <td>2016-08-02T15:39:07.163</td>\n",
       "      <td>John Slegers</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2016-08-24T12:04:27.477</td>\n",
       "      <td>Leuven, Belgium</td>\n",
       "      <td>119</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>https://i.stack.imgur.com/mRsBv.png?s=128&amp;g=1</td>\n",
       "      <td>http://www.johnslegers.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>5821510</td>\n",
       "      <td>2016-08-02T15:39:10.913</td>\n",
       "      <td>Slam</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>2016-08-02T18:20:47.073</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/8ca0a23494d4c5...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;h2&gt;&lt;a href=\"https://github.co...</td>\n",
       "      <td>5972730</td>\n",
       "      <td>2016-08-02T15:39:11.220</td>\n",
       "      <td>Mateusz Piotrowski</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2016-11-16T22:57:47.327</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>https://i.stack.imgur.com/lIYBa.png?s=128&amp;g=1</td>\n",
       "      <td>https://wiki.freebsd.org/MateuszPiotrowski</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1293467</td>\n",
       "      <td>2016-08-02T15:39:27.143</td>\n",
       "      <td>Sepideh Abadpour</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>2017-04-12T22:41:24.513</td>\n",
       "      <td>Iran</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>http://area51.stackexchange.com/proposals/9032...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>&lt;p&gt;Accidental coder with a cynical view of cod...</td>\n",
       "      <td>735810</td>\n",
       "      <td>2016-08-02T15:39:36.307</td>\n",
       "      <td>EdChum - Reinstate Monica</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>2016-08-02T15:39:36.307</td>\n",
       "      <td>Berkshire, United Kingdom</td>\n",
       "      <td>101</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;BY DAY:&lt;/strong&gt; Jack of all trades...</td>\n",
       "      <td>2163836</td>\n",
       "      <td>2016-08-02T15:39:37.220</td>\n",
       "      <td>applecrusher</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2016-08-02T15:39:37.220</td>\n",
       "      <td>Troy, NY, United States</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0</td>\n",
       "      <td>2581963</td>\n",
       "      <td>2016-08-02T15:39:39.870</td>\n",
       "      <td>TheBrenny</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2020-01-17T09:12:00.107</td>\n",
       "      <td>Darwin, Australia</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/69e1b60c089cfb...</td>\n",
       "      <td>http://brennytizer.com.au</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>&lt;p&gt;Fullstack developer and gamer&lt;/p&gt;\\n\\n&lt;p&gt;&lt;a ...</td>\n",
       "      <td>3727293</td>\n",
       "      <td>2016-08-02T15:39:54.913</td>\n",
       "      <td>jasilva</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2016-08-22T13:46:11.100</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/37tpy.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>&lt;p&gt;developer, techie, nerd.... DBA at Stack Ov...</td>\n",
       "      <td>188123</td>\n",
       "      <td>2016-08-02T15:40:06.357</td>\n",
       "      <td>Taryn</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2017-08-16T20:17:50.187</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://tarynpivots.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>&lt;p&gt;Former &lt;a href=\"https://stackoverflow.blog/...</td>\n",
       "      <td>1190</td>\n",
       "      <td>2016-08-02T15:40:18.553</td>\n",
       "      <td>Oded</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2017-10-18T09:40:41.117</td>\n",
       "      <td>London, United Kingdom</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/Au4eT.png?s=128&amp;g=1</td>\n",
       "      <td>http://OdedCoster.com/blog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>&lt;p&gt;I am a school student with great interest i...</td>\n",
       "      <td>6343509</td>\n",
       "      <td>2016-08-02T15:40:27.977</td>\n",
       "      <td>tatan</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>2019-11-15T06:11:47.217</td>\n",
       "      <td>India</td>\n",
       "      <td>379</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>https://www.gravatar.com/avatar/deb314ef0b51a5...</td>\n",
       "      <td>http://Email:-sohamrwik@hotmail.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Bjorn&lt;/strong&gt; (English),&lt;br&gt;\\n&lt;str...</td>\n",
       "      <td>176996</td>\n",
       "      <td>2016-08-02T15:40:38.907</td>\n",
       "      <td>Bjørn-Roger Kringsjå</td>\n",
       "      <td>2</td>\n",
       "      <td>27</td>\n",
       "      <td>2017-12-03T18:28:36.170</td>\n",
       "      <td>Skien, Norway</td>\n",
       "      <td>101</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>http://stackoverflow.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>&lt;blockquote&gt;\\n  &lt;p&gt;Each working data pipeline ...</td>\n",
       "      <td>32277</td>\n",
       "      <td>2016-08-02T15:40:40.850</td>\n",
       "      <td>miku</td>\n",
       "      <td>0</td>\n",
       "      <td>28</td>\n",
       "      <td>2019-11-25T15:12:38.617</td>\n",
       "      <td>Germany</td>\n",
       "      <td>680</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>&lt;p&gt;I am a Dutch amateur mathematician currentl...</td>\n",
       "      <td>6241661</td>\n",
       "      <td>2016-08-02T15:40:44.807</td>\n",
       "      <td>wythagoras</td>\n",
       "      <td>9</td>\n",
       "      <td>29</td>\n",
       "      <td>2018-11-17T16:47:39.420</td>\n",
       "      <td>0</td>\n",
       "      <td>1361</td>\n",
       "      <td>112</td>\n",
       "      <td>55</td>\n",
       "      <td>https://i.stack.imgur.com/JfeF9.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>8692869</td>\n",
       "      <td>2016-08-02T15:41:02.680</td>\n",
       "      <td>Disenchanted Lurker</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>2019-08-28T08:20:44.920</td>\n",
       "      <td>0</td>\n",
       "      <td>755</td>\n",
       "      <td>18</td>\n",
       "      <td>11</td>\n",
       "      <td>https://i.stack.imgur.com/YEyuc.png?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29343</th>\n",
       "      <td>0</td>\n",
       "      <td>2197940</td>\n",
       "      <td>2020-02-29T02:05:36.073</td>\n",
       "      <td>Khan Immran</td>\n",
       "      <td>0</td>\n",
       "      <td>33894</td>\n",
       "      <td>2020-02-29T02:05:36.073</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/ed94f8252fe602...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29344</th>\n",
       "      <td>0</td>\n",
       "      <td>16027679</td>\n",
       "      <td>2020-02-29T02:23:10.787</td>\n",
       "      <td>Denn</td>\n",
       "      <td>0</td>\n",
       "      <td>33895</td>\n",
       "      <td>2020-02-29T02:23:10.787</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/8df99bd695c73d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29345</th>\n",
       "      <td>0</td>\n",
       "      <td>17871459</td>\n",
       "      <td>2020-02-29T02:39:21.533</td>\n",
       "      <td>mdoyle</td>\n",
       "      <td>0</td>\n",
       "      <td>33896</td>\n",
       "      <td>2020-02-29T02:39:21.533</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/24a390aa089190...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29346</th>\n",
       "      <td>0</td>\n",
       "      <td>1745384</td>\n",
       "      <td>2020-02-29T03:16:51.397</td>\n",
       "      <td>goncalopp</td>\n",
       "      <td>0</td>\n",
       "      <td>33897</td>\n",
       "      <td>2020-02-29T20:53:11.113</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>https://www.gravatar.com/avatar/145be364a8062d...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29347</th>\n",
       "      <td>&lt;p&gt;What you got ain’t nothin’ new.&lt;/p&gt;\\n\\n&lt;p&gt;T...</td>\n",
       "      <td>501236</td>\n",
       "      <td>2020-02-29T04:49:13.837</td>\n",
       "      <td>Steven Penny</td>\n",
       "      <td>0</td>\n",
       "      <td>33898</td>\n",
       "      <td>2020-02-29T04:49:13.837</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/5ec9c21c8d5482...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29348</th>\n",
       "      <td>0</td>\n",
       "      <td>3104732</td>\n",
       "      <td>2020-02-29T05:21:11.270</td>\n",
       "      <td>MindSeeker</td>\n",
       "      <td>0</td>\n",
       "      <td>33899</td>\n",
       "      <td>2020-02-29T05:21:11.270</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/88d99226af8521...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29349</th>\n",
       "      <td>&lt;p&gt;Looking for kitchen cabinets in Calgary? Fi...</td>\n",
       "      <td>16997141</td>\n",
       "      <td>2020-02-29T05:22:11.027</td>\n",
       "      <td>Cowry Cabinets Calgary Ltd</td>\n",
       "      <td>0</td>\n",
       "      <td>33900</td>\n",
       "      <td>2020-02-29T06:14:30.500</td>\n",
       "      <td>6424 1a St SW, Calgary, AB, Canada</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/ZRdEH.png?s=128&amp;g=1</td>\n",
       "      <td>http://www.cowrycabinetscalgary.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29350</th>\n",
       "      <td>0</td>\n",
       "      <td>17872069</td>\n",
       "      <td>2020-02-29T05:44:14.727</td>\n",
       "      <td>Jason</td>\n",
       "      <td>0</td>\n",
       "      <td>33901</td>\n",
       "      <td>2020-02-29T17:24:11.117</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29351</th>\n",
       "      <td>0</td>\n",
       "      <td>17265895</td>\n",
       "      <td>2020-02-29T05:47:23.150</td>\n",
       "      <td>bluewander</td>\n",
       "      <td>0</td>\n",
       "      <td>33902</td>\n",
       "      <td>2020-02-29T05:47:23.150</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/a4b10d7337a000...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29352</th>\n",
       "      <td>&lt;p&gt;Complete Restoration and Construction is a ...</td>\n",
       "      <td>17632442</td>\n",
       "      <td>2020-02-29T06:15:40.513</td>\n",
       "      <td>Crcrestoration</td>\n",
       "      <td>0</td>\n",
       "      <td>33903</td>\n",
       "      <td>2020-02-29T06:15:40.513</td>\n",
       "      <td>PO BOX 9094,  Yakima, WA, 98908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/6e9d1cb85782a2...</td>\n",
       "      <td>https://www.crcrestoration.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29353</th>\n",
       "      <td>&lt;p&gt;Machine Learning • Remote Work • Frontend&lt;/...</td>\n",
       "      <td>7711974</td>\n",
       "      <td>2020-02-29T06:22:34.063</td>\n",
       "      <td>Darshan Jain</td>\n",
       "      <td>0</td>\n",
       "      <td>33904</td>\n",
       "      <td>2020-02-29T07:25:54.787</td>\n",
       "      <td>Mumbai, Maharashtra, India</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/LtTD1.jpg?s=128&amp;g=1</td>\n",
       "      <td>https://www.linkedin.com/in/darshanjain29/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29354</th>\n",
       "      <td>&lt;p&gt;Professional iOS and Flutter developer.&lt;/p&gt;\\n</td>\n",
       "      <td>9957768</td>\n",
       "      <td>2020-02-29T07:01:54.633</td>\n",
       "      <td>Sandeep Maurya</td>\n",
       "      <td>0</td>\n",
       "      <td>33905</td>\n",
       "      <td>2020-02-29T07:26:25.327</td>\n",
       "      <td>Surat, Gujarat, India</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh4.googleusercontent.com/-HLBwUxQYQ5s...</td>\n",
       "      <td>https://www.linkedin.com/in/sandeep-maurya-448...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29355</th>\n",
       "      <td>0</td>\n",
       "      <td>14224250</td>\n",
       "      <td>2020-02-29T07:20:56.243</td>\n",
       "      <td>Công ty TNHH Đổi Mệnh Phát tài</td>\n",
       "      <td>0</td>\n",
       "      <td>33906</td>\n",
       "      <td>2020-02-29T07:20:56.243</td>\n",
       "      <td>Việt Nam</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh6.googleusercontent.com/-CifM_qM0bNc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29356</th>\n",
       "      <td>0</td>\n",
       "      <td>17512003</td>\n",
       "      <td>2020-02-29T07:39:26.907</td>\n",
       "      <td>Aditya Iyer</td>\n",
       "      <td>0</td>\n",
       "      <td>33907</td>\n",
       "      <td>2020-02-29T08:04:58.810</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh3.googleusercontent.com/a-/AAuE7mC41...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29357</th>\n",
       "      <td>0</td>\n",
       "      <td>221336</td>\n",
       "      <td>2020-02-29T07:43:52.897</td>\n",
       "      <td>Pac0</td>\n",
       "      <td>0</td>\n",
       "      <td>33908</td>\n",
       "      <td>2020-02-29T07:43:52.897</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/9870fa7c3f578b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29358</th>\n",
       "      <td>0</td>\n",
       "      <td>16168259</td>\n",
       "      <td>2020-02-29T08:00:52.677</td>\n",
       "      <td>Hamza</td>\n",
       "      <td>0</td>\n",
       "      <td>33909</td>\n",
       "      <td>2020-02-29T15:44:54.570</td>\n",
       "      <td>Lahore, Pakistan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/facf414c43e15e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29359</th>\n",
       "      <td>&lt;p&gt;A T-shaped engineer exploring the multidisc...</td>\n",
       "      <td>14034262</td>\n",
       "      <td>2020-02-29T08:22:33.207</td>\n",
       "      <td>Amit Chaudhary</td>\n",
       "      <td>0</td>\n",
       "      <td>33910</td>\n",
       "      <td>2020-02-29T16:47:25.690</td>\n",
       "      <td>Kathmandu, Nepal</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>https://lh6.googleusercontent.com/-JpnDNLhZLU4...</td>\n",
       "      <td>https://amitness.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29360</th>\n",
       "      <td>0</td>\n",
       "      <td>17872677</td>\n",
       "      <td>2020-02-29T09:01:32.300</td>\n",
       "      <td>Rehan</td>\n",
       "      <td>0</td>\n",
       "      <td>33911</td>\n",
       "      <td>2020-02-29T09:01:32.300</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/c199e39d6ba6fa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29361</th>\n",
       "      <td>&lt;p&gt;I took Master of Computer Science at Shahid...</td>\n",
       "      <td>13876378</td>\n",
       "      <td>2020-02-29T10:01:46.037</td>\n",
       "      <td>amin</td>\n",
       "      <td>0</td>\n",
       "      <td>33912</td>\n",
       "      <td>2020-02-29T10:01:46.037</td>\n",
       "      <td>Tehran, Tehran Province, Iran</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/4He2u.jpg?s=128&amp;g=1</td>\n",
       "      <td>https://www.linkedin.com/in/mohammad-amin-khod...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29362</th>\n",
       "      <td>0</td>\n",
       "      <td>69601</td>\n",
       "      <td>2020-02-29T10:21:52.703</td>\n",
       "      <td>Shankar Nathan</td>\n",
       "      <td>0</td>\n",
       "      <td>33913</td>\n",
       "      <td>2020-02-29T10:21:52.703</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/a9830587d239a0...</td>\n",
       "      <td>http://www.tapfantasy.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29363</th>\n",
       "      <td>0</td>\n",
       "      <td>11411846</td>\n",
       "      <td>2020-02-29T10:47:14.893</td>\n",
       "      <td>miGa77</td>\n",
       "      <td>0</td>\n",
       "      <td>33914</td>\n",
       "      <td>2020-02-29T10:47:14.893</td>\n",
       "      <td>Aachen, Germany</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/xb3nR.jpg?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29364</th>\n",
       "      <td>&lt;p&gt;Software architect &amp;amp; Python developer s...</td>\n",
       "      <td>4790551</td>\n",
       "      <td>2020-02-29T11:25:57.620</td>\n",
       "      <td>Soham Navadiya</td>\n",
       "      <td>0</td>\n",
       "      <td>33915</td>\n",
       "      <td>2020-02-29T11:25:57.620</td>\n",
       "      <td>India</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/bdd06ab138188a...</td>\n",
       "      <td>https://raunakgroup.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29365</th>\n",
       "      <td>&lt;p&gt;&lt;strong&gt;Foundations&lt;/strong&gt;&lt;/p&gt;\\n\\n&lt;ul&gt;\\n&lt;...</td>\n",
       "      <td>1131127</td>\n",
       "      <td>2020-02-29T15:48:42.413</td>\n",
       "      <td>user21820</td>\n",
       "      <td>0</td>\n",
       "      <td>33916</td>\n",
       "      <td>2020-02-29T16:03:44.063</td>\n",
       "      <td>0</td>\n",
       "      <td>131</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/016f3df2c1ded9...</td>\n",
       "      <td>https://chat.stackexchange.com/rooms/44058/logic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29366</th>\n",
       "      <td>&lt;p&gt;Studying Software Engineering&lt;/p&gt;\\n</td>\n",
       "      <td>10415575</td>\n",
       "      <td>2020-02-29T17:04:39.530</td>\n",
       "      <td>Hamza Mohammad Khan</td>\n",
       "      <td>0</td>\n",
       "      <td>33917</td>\n",
       "      <td>2020-02-29T17:04:39.530</td>\n",
       "      <td>Karachi, Pakistan</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://graph.facebook.com/1459078027459216/pi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29367</th>\n",
       "      <td>0</td>\n",
       "      <td>14023876</td>\n",
       "      <td>2020-02-29T18:12:39.193</td>\n",
       "      <td>NaramukAbus</td>\n",
       "      <td>0</td>\n",
       "      <td>33918</td>\n",
       "      <td>2020-02-29T18:12:39.193</td>\n",
       "      <td>Colombo, Sri Lanka</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/BTniC.jpg?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29368</th>\n",
       "      <td>&lt;h1&gt;PETER MANGELSDORF&lt;/h1&gt;\\n\\n&lt;h2&gt;BS of Comput...</td>\n",
       "      <td>16838470</td>\n",
       "      <td>2020-02-29T19:55:56.380</td>\n",
       "      <td>Peter Mangelsdorf</td>\n",
       "      <td>0</td>\n",
       "      <td>33919</td>\n",
       "      <td>2020-02-29T19:55:56.380</td>\n",
       "      <td>Philadelphia, PA, USA</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/NckyU.jpg?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29369</th>\n",
       "      <td>0</td>\n",
       "      <td>5968867</td>\n",
       "      <td>2020-02-29T20:02:12.597</td>\n",
       "      <td>Joooeey</td>\n",
       "      <td>0</td>\n",
       "      <td>33920</td>\n",
       "      <td>2020-02-29T22:12:39.087</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh4.googleusercontent.com/-lqbwtD6n1nc...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29370</th>\n",
       "      <td>0</td>\n",
       "      <td>1198139</td>\n",
       "      <td>2020-02-29T20:25:06.190</td>\n",
       "      <td>user1169420</td>\n",
       "      <td>0</td>\n",
       "      <td>33921</td>\n",
       "      <td>2020-02-29T21:57:01.343</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://www.gravatar.com/avatar/4a4c4da37c032c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29371</th>\n",
       "      <td>0</td>\n",
       "      <td>4891758</td>\n",
       "      <td>2020-02-29T20:39:18.573</td>\n",
       "      <td>feihcsim</td>\n",
       "      <td>0</td>\n",
       "      <td>33922</td>\n",
       "      <td>2020-02-29T20:39:18.573</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>https://i.stack.imgur.com/bVbLj.jpg?s=128&amp;g=1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29372</th>\n",
       "      <td>&lt;p&gt;I am the author of &lt;a href=\"https://github....</td>\n",
       "      <td>5456847</td>\n",
       "      <td>2020-02-29T21:24:22.110</td>\n",
       "      <td>lirtosiast</td>\n",
       "      <td>0</td>\n",
       "      <td>33923</td>\n",
       "      <td>2020-02-29T21:24:22.110</td>\n",
       "      <td>Inside your computer</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://lh5.googleusercontent.com/-_FtDudLYxfA...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>29373 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 AboutMe AccountId  \\\n",
       "0      <p>Hi, I'm not really a person.</p>\\n<p>I'm a ...        -1   \n",
       "1      \\n\\n<p>Developer at Stack Overflow focusing on...     37099   \n",
       "2      <p>I am the Architecture Lead for Stack Overfl...      7598   \n",
       "3      <p>Developer on the Stack Overflow team.  Find...         2   \n",
       "4      <p><a href=\"https://stackexchange.com/users/16...    169656   \n",
       "5                                                      0   8057826   \n",
       "6                                                      0   3393940   \n",
       "7                                                      0   6824864   \n",
       "8      <p>I'm IT engineer programming in anything tha...     22370   \n",
       "9      <p>Computer Science undergraduate at the Unive...   7263447   \n",
       "10     <p>Staff Writer at Machine Intelligence Resear...    555192   \n",
       "11     <p>Duke graduate with BSE in Electrical and Co...   4031433   \n",
       "12                            <p>Software Engineer</p>\\n   6064666   \n",
       "13     <p>I'm a student in shahid maddani high school...   8247602   \n",
       "14                                                     0    949428   \n",
       "15     <p><a href=\"https://www.linkedin.com/pulse/eat...   2202424   \n",
       "16                                                     0   5821510   \n",
       "17     <blockquote>\\n  <h2><a href=\"https://github.co...   5972730   \n",
       "18                                                     0   1293467   \n",
       "19     <p>Accidental coder with a cynical view of cod...    735810   \n",
       "20     <p><strong>BY DAY:</strong> Jack of all trades...   2163836   \n",
       "21                                                     0   2581963   \n",
       "22     <p>Fullstack developer and gamer</p>\\n\\n<p><a ...   3727293   \n",
       "23     <p>developer, techie, nerd.... DBA at Stack Ov...    188123   \n",
       "24     <p>Former <a href=\"https://stackoverflow.blog/...      1190   \n",
       "25     <p>I am a school student with great interest i...   6343509   \n",
       "26     <p><strong>Bjorn</strong> (English),<br>\\n<str...    176996   \n",
       "27     <blockquote>\\n  <p>Each working data pipeline ...     32277   \n",
       "28     <p>I am a Dutch amateur mathematician currentl...   6241661   \n",
       "29                                                     0   8692869   \n",
       "...                                                  ...       ...   \n",
       "29343                                                  0   2197940   \n",
       "29344                                                  0  16027679   \n",
       "29345                                                  0  17871459   \n",
       "29346                                                  0   1745384   \n",
       "29347  <p>What you got ain’t nothin’ new.</p>\\n\\n<p>T...    501236   \n",
       "29348                                                  0   3104732   \n",
       "29349  <p>Looking for kitchen cabinets in Calgary? Fi...  16997141   \n",
       "29350                                                  0  17872069   \n",
       "29351                                                  0  17265895   \n",
       "29352  <p>Complete Restoration and Construction is a ...  17632442   \n",
       "29353  <p>Machine Learning • Remote Work • Frontend</...   7711974   \n",
       "29354   <p>Professional iOS and Flutter developer.</p>\\n   9957768   \n",
       "29355                                                  0  14224250   \n",
       "29356                                                  0  17512003   \n",
       "29357                                                  0    221336   \n",
       "29358                                                  0  16168259   \n",
       "29359  <p>A T-shaped engineer exploring the multidisc...  14034262   \n",
       "29360                                                  0  17872677   \n",
       "29361  <p>I took Master of Computer Science at Shahid...  13876378   \n",
       "29362                                                  0     69601   \n",
       "29363                                                  0  11411846   \n",
       "29364  <p>Software architect &amp; Python developer s...   4790551   \n",
       "29365  <p><strong>Foundations</strong></p>\\n\\n<ul>\\n<...   1131127   \n",
       "29366             <p>Studying Software Engineering</p>\\n  10415575   \n",
       "29367                                                  0  14023876   \n",
       "29368  <h1>PETER MANGELSDORF</h1>\\n\\n<h2>BS of Comput...  16838470   \n",
       "29369                                                  0   5968867   \n",
       "29370                                                  0   1198139   \n",
       "29371                                                  0   4891758   \n",
       "29372  <p>I am the author of <a href=\"https://github....   5456847   \n",
       "\n",
       "                  CreationDate                     DisplayName DownVotes  \\\n",
       "0      2016-08-02T00:14:10.580                       Community       876   \n",
       "1      2016-08-02T15:36:45.333                       Adam Lear         0   \n",
       "2      2016-08-02T15:36:48.397                     Nick Craver         0   \n",
       "3      2016-08-02T15:38:01.633                    Geoff Dalgas         0   \n",
       "4      2016-08-02T15:38:21.100              Franck Dernoncourt         2   \n",
       "5      2016-08-02T15:38:27.643                    baranskistad         1   \n",
       "6      2016-08-02T15:38:27.847                             Dom        30   \n",
       "7      2016-08-02T15:38:28.443                     Ben Clayton         0   \n",
       "8      2016-08-02T15:38:36.723                          kenorb         3   \n",
       "9      2016-08-02T15:38:37.287                      Rob Murray         0   \n",
       "10     2016-08-02T15:38:37.680                  Matthew Graves        25   \n",
       "11     2016-08-02T15:38:48.693              Abhishek Upadhyaya         0   \n",
       "12     2016-08-02T15:38:54.597                        Jouramie         0   \n",
       "13     2016-08-02T15:38:58.930                     Taha Akbari         0   \n",
       "14     2016-08-02T15:39:06.707                      CarrKnight         0   \n",
       "15     2016-08-02T15:39:07.163                    John Slegers         0   \n",
       "16     2016-08-02T15:39:10.913                            Slam         0   \n",
       "17     2016-08-02T15:39:11.220              Mateusz Piotrowski         0   \n",
       "18     2016-08-02T15:39:27.143                Sepideh Abadpour         0   \n",
       "19     2016-08-02T15:39:36.307       EdChum - Reinstate Monica         0   \n",
       "20     2016-08-02T15:39:37.220                    applecrusher         0   \n",
       "21     2016-08-02T15:39:39.870                       TheBrenny         0   \n",
       "22     2016-08-02T15:39:54.913                         jasilva         0   \n",
       "23     2016-08-02T15:40:06.357                           Taryn         0   \n",
       "24     2016-08-02T15:40:18.553                            Oded         0   \n",
       "25     2016-08-02T15:40:27.977                           tatan         0   \n",
       "26     2016-08-02T15:40:38.907            Bjørn-Roger Kringsjå         2   \n",
       "27     2016-08-02T15:40:40.850                            miku         0   \n",
       "28     2016-08-02T15:40:44.807                      wythagoras         9   \n",
       "29     2016-08-02T15:41:02.680             Disenchanted Lurker         1   \n",
       "...                        ...                             ...       ...   \n",
       "29343  2020-02-29T02:05:36.073                     Khan Immran         0   \n",
       "29344  2020-02-29T02:23:10.787                            Denn         0   \n",
       "29345  2020-02-29T02:39:21.533                          mdoyle         0   \n",
       "29346  2020-02-29T03:16:51.397                       goncalopp         0   \n",
       "29347  2020-02-29T04:49:13.837                    Steven Penny         0   \n",
       "29348  2020-02-29T05:21:11.270                      MindSeeker         0   \n",
       "29349  2020-02-29T05:22:11.027      Cowry Cabinets Calgary Ltd         0   \n",
       "29350  2020-02-29T05:44:14.727                           Jason         0   \n",
       "29351  2020-02-29T05:47:23.150                      bluewander         0   \n",
       "29352  2020-02-29T06:15:40.513                  Crcrestoration         0   \n",
       "29353  2020-02-29T06:22:34.063                    Darshan Jain         0   \n",
       "29354  2020-02-29T07:01:54.633                  Sandeep Maurya         0   \n",
       "29355  2020-02-29T07:20:56.243  Công ty TNHH Đổi Mệnh Phát tài         0   \n",
       "29356  2020-02-29T07:39:26.907                     Aditya Iyer         0   \n",
       "29357  2020-02-29T07:43:52.897                            Pac0         0   \n",
       "29358  2020-02-29T08:00:52.677                           Hamza         0   \n",
       "29359  2020-02-29T08:22:33.207                  Amit Chaudhary         0   \n",
       "29360  2020-02-29T09:01:32.300                           Rehan         0   \n",
       "29361  2020-02-29T10:01:46.037                            amin         0   \n",
       "29362  2020-02-29T10:21:52.703                  Shankar Nathan         0   \n",
       "29363  2020-02-29T10:47:14.893                          miGa77         0   \n",
       "29364  2020-02-29T11:25:57.620                  Soham Navadiya         0   \n",
       "29365  2020-02-29T15:48:42.413                       user21820         0   \n",
       "29366  2020-02-29T17:04:39.530             Hamza Mohammad Khan         0   \n",
       "29367  2020-02-29T18:12:39.193                     NaramukAbus         0   \n",
       "29368  2020-02-29T19:55:56.380               Peter Mangelsdorf         0   \n",
       "29369  2020-02-29T20:02:12.597                         Joooeey         0   \n",
       "29370  2020-02-29T20:25:06.190                     user1169420         0   \n",
       "29371  2020-02-29T20:39:18.573                        feihcsim         0   \n",
       "29372  2020-02-29T21:24:22.110                      lirtosiast         0   \n",
       "\n",
       "          Id           LastAccessDate                            Location  \\\n",
       "0         -1  2016-08-02T00:14:10.580                  on the server farm   \n",
       "1          1  2019-11-05T22:06:40.680                        New York, NY   \n",
       "2          2  2016-11-30T22:09:22.300                   Winston-Salem, NC   \n",
       "3          3  2018-01-09T03:22:26.573        Corvallis, OR, United States   \n",
       "4          4  2020-02-24T23:40:36.403   Adobe Research, San Jose, CA, USA   \n",
       "5          5  2019-07-21T04:30:14.580          Mankato, MN, United States   \n",
       "6          6  2019-09-17T21:30:49.600                    Philadelphia, PA   \n",
       "7          7  2019-11-12T11:49:22.170            Plymouth, United Kingdom   \n",
       "8          8  2020-02-28T20:59:24.207                                   0   \n",
       "9          9  2018-10-14T10:24:20.607                      United Kingdon   \n",
       "10        10  2019-12-02T23:24:15.707                          Austin, TX   \n",
       "11        12  2018-10-02T19:39:01.630                          Durham, NC   \n",
       "12        13  2016-08-15T15:50:04.147                  Québec, QC, Canada   \n",
       "13        14  2017-01-09T10:34:56.857       Tabriz, East Azerbaijan, Iran   \n",
       "14        15  2020-02-25T13:49:59.060                                   0   \n",
       "15        16  2016-08-24T12:04:27.477                     Leuven, Belgium   \n",
       "16        17  2016-08-02T18:20:47.073                                   0   \n",
       "17        18  2016-11-16T22:57:47.327                                   0   \n",
       "18        19  2017-04-12T22:41:24.513                                Iran   \n",
       "19        20  2016-08-02T15:39:36.307           Berkshire, United Kingdom   \n",
       "20        21  2016-08-02T15:39:37.220             Troy, NY, United States   \n",
       "21        22  2020-01-17T09:12:00.107                   Darwin, Australia   \n",
       "22        23  2016-08-22T13:46:11.100                                   0   \n",
       "23        24  2017-08-16T20:17:50.187                             Arizona   \n",
       "24        25  2017-10-18T09:40:41.117              London, United Kingdom   \n",
       "25        26  2019-11-15T06:11:47.217                               India   \n",
       "26        27  2017-12-03T18:28:36.170                       Skien, Norway   \n",
       "27        28  2019-11-25T15:12:38.617                             Germany   \n",
       "28        29  2018-11-17T16:47:39.420                                   0   \n",
       "29        30  2019-08-28T08:20:44.920                                   0   \n",
       "...      ...                      ...                                 ...   \n",
       "29343  33894  2020-02-29T02:05:36.073                                   0   \n",
       "29344  33895  2020-02-29T02:23:10.787                                   0   \n",
       "29345  33896  2020-02-29T02:39:21.533                                   0   \n",
       "29346  33897  2020-02-29T20:53:11.113                                   0   \n",
       "29347  33898  2020-02-29T04:49:13.837                                   0   \n",
       "29348  33899  2020-02-29T05:21:11.270                                   0   \n",
       "29349  33900  2020-02-29T06:14:30.500  6424 1a St SW, Calgary, AB, Canada   \n",
       "29350  33901  2020-02-29T17:24:11.117                                   0   \n",
       "29351  33902  2020-02-29T05:47:23.150                                   0   \n",
       "29352  33903  2020-02-29T06:15:40.513     PO BOX 9094,  Yakima, WA, 98908   \n",
       "29353  33904  2020-02-29T07:25:54.787          Mumbai, Maharashtra, India   \n",
       "29354  33905  2020-02-29T07:26:25.327               Surat, Gujarat, India   \n",
       "29355  33906  2020-02-29T07:20:56.243                            Việt Nam   \n",
       "29356  33907  2020-02-29T08:04:58.810                                   0   \n",
       "29357  33908  2020-02-29T07:43:52.897                         Switzerland   \n",
       "29358  33909  2020-02-29T15:44:54.570                    Lahore, Pakistan   \n",
       "29359  33910  2020-02-29T16:47:25.690                    Kathmandu, Nepal   \n",
       "29360  33911  2020-02-29T09:01:32.300                                   0   \n",
       "29361  33912  2020-02-29T10:01:46.037       Tehran, Tehran Province, Iran   \n",
       "29362  33913  2020-02-29T10:21:52.703                                   0   \n",
       "29363  33914  2020-02-29T10:47:14.893                     Aachen, Germany   \n",
       "29364  33915  2020-02-29T11:25:57.620                               India   \n",
       "29365  33916  2020-02-29T16:03:44.063                                   0   \n",
       "29366  33917  2020-02-29T17:04:39.530                   Karachi, Pakistan   \n",
       "29367  33918  2020-02-29T18:12:39.193                  Colombo, Sri Lanka   \n",
       "29368  33919  2020-02-29T19:55:56.380               Philadelphia, PA, USA   \n",
       "29369  33920  2020-02-29T22:12:39.087                                   0   \n",
       "29370  33921  2020-02-29T21:57:01.343                                   0   \n",
       "29371  33922  2020-02-29T20:39:18.573                                   0   \n",
       "29372  33923  2020-02-29T21:24:22.110                Inside your computer   \n",
       "\n",
       "      Reputation UpVotes Views  \\\n",
       "0              1       4     0   \n",
       "1            101       0   151   \n",
       "2            101       0    11   \n",
       "3            101       0    12   \n",
       "4           1736      15   110   \n",
       "5            429      30    19   \n",
       "6            101      12    12   \n",
       "7              1       3     5   \n",
       "8           8543     581   408   \n",
       "9            461       6     9   \n",
       "10          3919      64   245   \n",
       "11             1       1     3   \n",
       "12           101       0     1   \n",
       "13           101       0     1   \n",
       "14           191       4     2   \n",
       "15           119      41     4   \n",
       "16             1       0     0   \n",
       "17           101       3     1   \n",
       "18           101       0     0   \n",
       "19           101       2     0   \n",
       "20           101       0     0   \n",
       "21           101       0     0   \n",
       "22           101       0     0   \n",
       "23           101       0     0   \n",
       "24           101       0     0   \n",
       "25           379       1    19   \n",
       "26           101      19     1   \n",
       "27           680       6     7   \n",
       "28          1361     112    55   \n",
       "29           755      18    11   \n",
       "...          ...     ...   ...   \n",
       "29343          1       0     0   \n",
       "29344          1       0     0   \n",
       "29345          1       0     0   \n",
       "29346        101       0     1   \n",
       "29347        101       0     0   \n",
       "29348        101       0     0   \n",
       "29349          1       0     0   \n",
       "29350         21       0     0   \n",
       "29351          1       0     0   \n",
       "29352          1       0     0   \n",
       "29353          1       0     0   \n",
       "29354        101       0     0   \n",
       "29355          1       0     0   \n",
       "29356          1       0     0   \n",
       "29357        101       1     0   \n",
       "29358          1       0     0   \n",
       "29359          3       0     2   \n",
       "29360          1       0     0   \n",
       "29361          1       0     0   \n",
       "29362          1       0     0   \n",
       "29363          1       0     0   \n",
       "29364        101       0     0   \n",
       "29365        131       0     0   \n",
       "29366          1       0     0   \n",
       "29367          1       0     0   \n",
       "29368          1       0     0   \n",
       "29369        101       1     0   \n",
       "29370        101       0     0   \n",
       "29371        101       1     0   \n",
       "29372        101       0     0   \n",
       "\n",
       "                                         ProfileImageUrl  \\\n",
       "0                                                      0   \n",
       "1          https://i.stack.imgur.com/SMEGn.jpg?s=128&g=1   \n",
       "2          https://i.stack.imgur.com/nGCYr.jpg?s=128&g=1   \n",
       "3                    https://i.stack.imgur.com/nDllk.png   \n",
       "4          https://i.stack.imgur.com/Z99mk.jpg?s=128&g=1   \n",
       "5          https://i.stack.imgur.com/Kk1s7.png?s=128&g=1   \n",
       "6          https://i.stack.imgur.com/B7uhq.png?s=128&g=1   \n",
       "7          https://i.stack.imgur.com/4TIdl.jpg?s=128&g=1   \n",
       "8                                                      0   \n",
       "9                    https://i.stack.imgur.com/r4U5R.jpg   \n",
       "10     https://lh3.googleusercontent.com/-1Y0NrEQiNfE...   \n",
       "11         https://i.stack.imgur.com/gAeAy.jpg?s=128&g=1   \n",
       "12     https://lh3.googleusercontent.com/-uY2YHtpTr00...   \n",
       "13     https://www.gravatar.com/avatar/7ceee8455db052...   \n",
       "14                                                     0   \n",
       "15         https://i.stack.imgur.com/mRsBv.png?s=128&g=1   \n",
       "16     https://www.gravatar.com/avatar/8ca0a23494d4c5...   \n",
       "17         https://i.stack.imgur.com/lIYBa.png?s=128&g=1   \n",
       "18                                                     0   \n",
       "19                                                     0   \n",
       "20                                                     0   \n",
       "21     https://www.gravatar.com/avatar/69e1b60c089cfb...   \n",
       "22                   https://i.stack.imgur.com/37tpy.png   \n",
       "23                                                     0   \n",
       "24         https://i.stack.imgur.com/Au4eT.png?s=128&g=1   \n",
       "25     https://www.gravatar.com/avatar/deb314ef0b51a5...   \n",
       "26                                                     0   \n",
       "27                                                     0   \n",
       "28                   https://i.stack.imgur.com/JfeF9.png   \n",
       "29         https://i.stack.imgur.com/YEyuc.png?s=128&g=1   \n",
       "...                                                  ...   \n",
       "29343  https://www.gravatar.com/avatar/ed94f8252fe602...   \n",
       "29344  https://www.gravatar.com/avatar/8df99bd695c73d...   \n",
       "29345  https://www.gravatar.com/avatar/24a390aa089190...   \n",
       "29346  https://www.gravatar.com/avatar/145be364a8062d...   \n",
       "29347  https://www.gravatar.com/avatar/5ec9c21c8d5482...   \n",
       "29348  https://www.gravatar.com/avatar/88d99226af8521...   \n",
       "29349      https://i.stack.imgur.com/ZRdEH.png?s=128&g=1   \n",
       "29350                                                  0   \n",
       "29351  https://www.gravatar.com/avatar/a4b10d7337a000...   \n",
       "29352  https://www.gravatar.com/avatar/6e9d1cb85782a2...   \n",
       "29353      https://i.stack.imgur.com/LtTD1.jpg?s=128&g=1   \n",
       "29354  https://lh4.googleusercontent.com/-HLBwUxQYQ5s...   \n",
       "29355  https://lh6.googleusercontent.com/-CifM_qM0bNc...   \n",
       "29356  https://lh3.googleusercontent.com/a-/AAuE7mC41...   \n",
       "29357  https://www.gravatar.com/avatar/9870fa7c3f578b...   \n",
       "29358  https://www.gravatar.com/avatar/facf414c43e15e...   \n",
       "29359  https://lh6.googleusercontent.com/-JpnDNLhZLU4...   \n",
       "29360  https://www.gravatar.com/avatar/c199e39d6ba6fa...   \n",
       "29361      https://i.stack.imgur.com/4He2u.jpg?s=128&g=1   \n",
       "29362  https://www.gravatar.com/avatar/a9830587d239a0...   \n",
       "29363      https://i.stack.imgur.com/xb3nR.jpg?s=128&g=1   \n",
       "29364  https://www.gravatar.com/avatar/bdd06ab138188a...   \n",
       "29365  https://www.gravatar.com/avatar/016f3df2c1ded9...   \n",
       "29366  https://graph.facebook.com/1459078027459216/pi...   \n",
       "29367      https://i.stack.imgur.com/BTniC.jpg?s=128&g=1   \n",
       "29368      https://i.stack.imgur.com/NckyU.jpg?s=128&g=1   \n",
       "29369  https://lh4.googleusercontent.com/-lqbwtD6n1nc...   \n",
       "29370  https://www.gravatar.com/avatar/4a4c4da37c032c...   \n",
       "29371      https://i.stack.imgur.com/bVbLj.jpg?s=128&g=1   \n",
       "29372  https://lh5.googleusercontent.com/-_FtDudLYxfA...   \n",
       "\n",
       "                                              WebsiteUrl  \n",
       "0                                                      0  \n",
       "1                                                      0  \n",
       "2                           https://nickcraver.com/blog/  \n",
       "3                               http://stackoverflow.com  \n",
       "4                                  http://www.francky.me  \n",
       "5                        https://github.com/baranskistad  \n",
       "6                                            http://None  \n",
       "7                                   http://benclayton.me  \n",
       "8                                      http://ads.london  \n",
       "9      https://www.linkedin.com/in/robert-murray-994a...  \n",
       "10                                                        \n",
       "11                  https://abhishekupadhyaya.github.io/  \n",
       "12                                                     0  \n",
       "13                                                     0  \n",
       "14                                                     0  \n",
       "15                            http://www.johnslegers.com  \n",
       "16                                                     0  \n",
       "17            https://wiki.freebsd.org/MateuszPiotrowski  \n",
       "18     http://area51.stackexchange.com/proposals/9032...  \n",
       "19                                                     0  \n",
       "20                                                     0  \n",
       "21                             http://brennytizer.com.au  \n",
       "22                                                     0  \n",
       "23                               https://tarynpivots.com  \n",
       "24                            http://OdedCoster.com/blog  \n",
       "25                   http://Email:-sohamrwik@hotmail.com  \n",
       "26                              http://stackoverflow.com  \n",
       "27                                                     0  \n",
       "28                                                     0  \n",
       "29                                                     0  \n",
       "...                                                  ...  \n",
       "29343                                                  0  \n",
       "29344                                                  0  \n",
       "29345                                                  0  \n",
       "29346                                                  0  \n",
       "29347                                                  0  \n",
       "29348                                                  0  \n",
       "29349               http://www.cowrycabinetscalgary.com/  \n",
       "29350                                                  0  \n",
       "29351                                                  0  \n",
       "29352                    https://www.crcrestoration.com/  \n",
       "29353         https://www.linkedin.com/in/darshanjain29/  \n",
       "29354  https://www.linkedin.com/in/sandeep-maurya-448...  \n",
       "29355                                                  0  \n",
       "29356                                                  0  \n",
       "29357                                                  0  \n",
       "29358                                                  0  \n",
       "29359                               https://amitness.com  \n",
       "29360                                                  0  \n",
       "29361  https://www.linkedin.com/in/mohammad-amin-khod...  \n",
       "29362                          http://www.tapfantasy.com  \n",
       "29363                                                  0  \n",
       "29364                           https://raunakgroup.com/  \n",
       "29365   https://chat.stackexchange.com/rooms/44058/logic  \n",
       "29366                                                  0  \n",
       "29367                                                  0  \n",
       "29368                                                  0  \n",
       "29369                                                  0  \n",
       "29370                                                  0  \n",
       "29371                                                  0  \n",
       "29372                                                  0  \n",
       "\n",
       "[29373 rows x 13 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ujZrprzBjoF0"
   },
   "source": [
    "Users.xml dataset will be merged with Posts.xml data set \n",
    "\n",
    "*   They are merged from their joint parameter user id \n",
    "*   user id is \"Id\" parameter in User.xml data \"Owner User ID\" in Posts.xml data\n",
    "*   Both parameters first converted into int type \n",
    "*   There were 3909 unique ids which indicated there are 3909 different users who have asked questions in this data sets \n",
    "*   So the data frames were merged according to them\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c4j20COFqAd_"
   },
   "outputs": [],
   "source": [
    "users['Id'] = users['Id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Q8hwxGXuHIEO"
   },
   "outputs": [],
   "source": [
    "posts=q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "J8a4uchqqAl8"
   },
   "outputs": [],
   "source": [
    "posts['Owner User ID']=posts ['Owner User ID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "uwVXO24jqApl",
    "outputId": "3c1c2e27-0a2c-4ed8-b459-571d9663060c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3275"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posts['Owner User ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6bmPxwoFtvkj",
    "outputId": "c27df55a-6455-43e0-a265-a9140309d630"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29373"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users['Id'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "STpTn0LgqAuF"
   },
   "outputs": [],
   "source": [
    "intersection=set(users['Id']).intersection(set(posts['Owner User ID']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OWQdD-55qA0o",
    "outputId": "b04be5f8-db63-49cf-c928-564188bddb9f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3274"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(intersection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "57KoqlAzk_M5"
   },
   "source": [
    "New id was defined as \"Owner User ID\" from Posts.xml and \"Id\" User.xml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8qmCsjUqA5J"
   },
   "outputs": [],
   "source": [
    "posts['New Id']=posts['Owner User ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IqkUruXTuvt3"
   },
   "outputs": [],
   "source": [
    "users['New Id']=users['Id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AyvmBQfnlLby"
   },
   "source": [
    "To eliminate confusion on naming of parameters between user and posts data, parameter names have changed such as CreationDate to User Creation Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sOIxSe87u9U7"
   },
   "outputs": [],
   "source": [
    "users ['User Creation Date']=users ['CreationDate']\n",
    "users ['User Last Access Date']=users ['LastAccessDate']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "STjZIuzcsgyE"
   },
   "source": [
    "2 data sets were merged from their joint parameter (user id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C1VXmocyu9kW"
   },
   "outputs": [],
   "source": [
    "new=posts.merge(users,on=\"New Id\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cwomXk5znnM5"
   },
   "source": [
    "Also unnecessary Id parameters and Url parameters were eliminated.\n",
    "Creation Date and LastAccessDate were dropped since their updated with other parameters name above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ld2jgfPmWO5h"
   },
   "outputs": [],
   "source": [
    "newposts=new.drop(axis=1,columns=[\"Owner User ID\",\"AccountId\",\"DisplayName\",\"CreationDate\",\"Id\",\"LastAccessDate\",\"Location\",\"ProfileImageUrl\",\"WebsiteUrl\",\"AboutMe\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9p3BmgEOpi1e"
   },
   "source": [
    "Since our task is to make a prediction at the time the question asked, we did not use posts down votes and upvotes .Thus user downvotes upvotes are the only ones. For ease of use We have changed the parameter names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u-uu6PDgpg7U"
   },
   "outputs": [],
   "source": [
    "newposts['User DownVotes']=newposts['DownVotes']\n",
    "newposts['User UpVotes']=newposts['UpVotes']\n",
    "newposts['User Reputation']=newposts['Reputation']\n",
    "newposts['User Views']=newposts['Views']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WiI08_AGprNb"
   },
   "outputs": [],
   "source": [
    "newposts=newposts.drop(axis=1,columns=[\"DownVotes\",\"UpVotes\",\"Reputation\",\"Views\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 323
    },
    "colab_type": "code",
    "id": "6DHag0AqyamC",
    "outputId": "c6124fc6-13b0-4ca1-8e93-b7763d065431"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tags</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>IsAnswered</th>\n",
       "      <th>New Id</th>\n",
       "      <th>User Creation Date</th>\n",
       "      <th>User Last Access Date</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User Views</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>What is \"backprop\"?</td>\n",
       "      <td>&lt;p&gt;What does \"backprop\" mean? Is the \"backprop...</td>\n",
       "      <td>1</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;backpropagation&gt;&lt;terminology...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>3</td>\n",
       "      <td>581</td>\n",
       "      <td>8543</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How does noise affect generalization?</td>\n",
       "      <td>&lt;p&gt;Does increasing the noise in data help to i...</td>\n",
       "      <td>2</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;machine-learning&gt;&lt;statistica...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>3</td>\n",
       "      <td>581</td>\n",
       "      <td>8543</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>How to find the optimal number of neurons per ...</td>\n",
       "      <td>&lt;p&gt;When you're writing your algorithm, how do ...</td>\n",
       "      <td>4</td>\n",
       "      <td>&lt;deep-network&gt;&lt;search&gt;&lt;neurons&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>3</td>\n",
       "      <td>581</td>\n",
       "      <td>8543</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>What is fuzzy logic?</td>\n",
       "      <td>&lt;p&gt;I'm new to A.I. and I'd like to know in sim...</td>\n",
       "      <td>10</td>\n",
       "      <td>&lt;deep-network&gt;&lt;terminology&gt;&lt;fuzzy-logic&gt;</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>3</td>\n",
       "      <td>581</td>\n",
       "      <td>8543</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>What is \"early stopping\" in machine learning?</td>\n",
       "      <td>&lt;p&gt;What is &lt;a href=\"https://en.wikipedia.org/w...</td>\n",
       "      <td>16</td>\n",
       "      <td>&lt;deep-learning&gt;&lt;definitions&gt;&lt;overfitting&gt;&lt;regu...</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2020-02-28T20:59:24.207</td>\n",
       "      <td>3</td>\n",
       "      <td>581</td>\n",
       "      <td>8543</td>\n",
       "      <td>408</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreationDate_1  CreationDate_2  CreationDate_3  \\\n",
       "0             1.0             0.0             0.0   \n",
       "1             1.0             0.0             0.0   \n",
       "2             1.0             0.0             0.0   \n",
       "3             1.0             0.0             0.0   \n",
       "4             1.0             0.0             0.0   \n",
       "\n",
       "                                               Title  \\\n",
       "0                                What is \"backprop\"?   \n",
       "1              How does noise affect generalization?   \n",
       "2  How to find the optimal number of neurons per ...   \n",
       "3                               What is fuzzy logic?   \n",
       "4      What is \"early stopping\" in machine learning?   \n",
       "\n",
       "                                                Body  ID  \\\n",
       "0  <p>What does \"backprop\" mean? Is the \"backprop...   1   \n",
       "1  <p>Does increasing the noise in data help to i...   2   \n",
       "2  <p>When you're writing your algorithm, how do ...   4   \n",
       "3  <p>I'm new to A.I. and I'd like to know in sim...  10   \n",
       "4  <p>What is <a href=\"https://en.wikipedia.org/w...  16   \n",
       "\n",
       "                                                Tags  Tag Count IsAnswered  \\\n",
       "0  <neural-networks><backpropagation><terminology...          4          1   \n",
       "1  <neural-networks><machine-learning><statistica...          4          1   \n",
       "2                    <deep-network><search><neurons>          3          1   \n",
       "3           <deep-network><terminology><fuzzy-logic>          3          1   \n",
       "4  <deep-learning><definitions><overfitting><regu...          5          1   \n",
       "\n",
       "   New Id       User Creation Date    User Last Access Date User DownVotes  \\\n",
       "0       8  2016-08-02T15:38:36.723  2020-02-28T20:59:24.207              3   \n",
       "1       8  2016-08-02T15:38:36.723  2020-02-28T20:59:24.207              3   \n",
       "2       8  2016-08-02T15:38:36.723  2020-02-28T20:59:24.207              3   \n",
       "3       8  2016-08-02T15:38:36.723  2020-02-28T20:59:24.207              3   \n",
       "4       8  2016-08-02T15:38:36.723  2020-02-28T20:59:24.207              3   \n",
       "\n",
       "  User UpVotes User Reputation User Views  \n",
       "0          581            8543        408  \n",
       "1          581            8543        408  \n",
       "2          581            8543        408  \n",
       "3          581            8543        408  \n",
       "4          581            8543        408  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newposts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hzcx97q546nD"
   },
   "outputs": [],
   "source": [
    "newposts['User Creation Date'] = pd.to_datetime(newposts['User Creation Date'])\n",
    "newposts['User Last Access Date'] = pd.to_datetime(newposts['User Last Access Date'])\n",
    "newposts['New Id'] = newposts['New Id'].astype(int)\n",
    "newposts['User DownVotes'] = newposts['User DownVotes'].astype(int)\n",
    "newposts['User UpVotes'] = newposts['User UpVotes'].astype(int)\n",
    "newposts['User Reputation'] = newposts['User Reputation'].astype(int)\n",
    "newposts['User Views'] = newposts['User Views'].astype(int)\n",
    "newposts['ID'] = newposts['ID'].astype(int)\n",
    "newposts['IsAnswered']=newposts['IsAnswered'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 306
    },
    "colab_type": "code",
    "id": "fHg-fimW473J",
    "outputId": "d441728a-82da-42d3-81fb-0e65107dd626"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CreationDate_1                  float64\n",
       "CreationDate_2                  float64\n",
       "CreationDate_3                  float64\n",
       "Title                            object\n",
       "Body                             object\n",
       "ID                                int32\n",
       "Tags                             object\n",
       "Tag Count                         int64\n",
       "IsAnswered                        int32\n",
       "New Id                            int32\n",
       "User Creation Date       datetime64[ns]\n",
       "User Last Access Date    datetime64[ns]\n",
       "User DownVotes                    int32\n",
       "User UpVotes                      int32\n",
       "User Reputation                   int32\n",
       "User Views                        int32\n",
       "dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newposts.dtypes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KR5pBSUPoiPA"
   },
   "source": [
    "Label encoding on dates implemented on User creation date and user last acces date also."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jGd1ZwHI4D0d"
   },
   "outputs": [],
   "source": [
    "def get_part_of_day(x):\n",
    "    return (\n",
    "        \"1\" if 5 <= int(x.strftime('%H')) <= 10\n",
    "        else\n",
    "        \"2\" if 11<=  int(x.strftime('%H'))<= 16\n",
    "        else\n",
    "        \"3\" if 17 <= int(x.strftime('%H'))  <= 22\n",
    "        else\n",
    "        \"4\"\n",
    "    )\n",
    "    \n",
    "newposts[\"User Creation Date\"] = newposts[\"User Creation Date\"].apply(get_part_of_day)\n",
    "newposts[\"User Last Access Date\"] = newposts[\"User Last Access Date\"].apply(get_part_of_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Z-Ozuk2p3mw"
   },
   "source": [
    "one hot encoding implemented on user.xml date format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EM7sGNPIowG1"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories = \"auto\",sparse = False, drop = \"first\")\n",
    "# One-Hot-Encode Class column of df\n",
    "temp = ohe.fit_transform(newposts[[\"User Creation Date\"]])\n",
    "\n",
    "\n",
    "# Converting into dataframe\n",
    "ohe_column = pd.DataFrame(temp, columns = [\"UserCreationDate_1\",\"UserCreationDate_2\",\"UserCreationDate_3\"])\n",
    "#containating ohe column\n",
    "newposts= pd.concat([newposts,ohe_column],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HSYtRsLYo1D7"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(categories = \"auto\",sparse = False, drop = \"first\")\n",
    "# One-Hot-Encode Class column of df\n",
    "temp = ohe.fit_transform(newposts[[\"User Last Access Date\"]])\n",
    "\n",
    "\n",
    "# Converting into dataframe\n",
    "ohe_column = pd.DataFrame(temp, columns = [\"UserLastAccessDate_1\",\"UserLastAccessDate_2\",\"UserLastAccessDate_3\"])\n",
    "#containating ohe column\n",
    "newposts= pd.concat([newposts,ohe_column],axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQfIul7SvUHH"
   },
   "outputs": [],
   "source": [
    "newposts=newposts.drop(axis=1, columns=[\"User Creation Date\",\"User Last Access Date\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fwDdGp68p-0E"
   },
   "source": [
    " xml tags are eliminated from tags to be used and preprocessing applied on text before they are added to data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IF6YpGUMZx6C"
   },
   "outputs": [],
   "source": [
    "newposts['Tags'] = newposts['Tags'].str.replace('<', '')\n",
    "newposts['Tags'] = newposts['Tags'].str.replace('>', ' ')\n",
    "newposts['Tags'] = newposts['Tags'].str.replace('-', ' ')\n",
    "newposts['Tags'] = newposts['Tags'].str.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "qCjLVk3ObYAE",
    "outputId": "e68ab1a0-78fb-476e-ca99-27a144ffc085"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [neural, networks, backpropagation, terminolog...\n",
       "1       [neural, networks, machine, learning, statisti...\n",
       "2                      [deep, network, search, neurons, ]\n",
       "3            [deep, network, terminology, fuzzy, logic, ]\n",
       "4       [deep, learning, definitions, overfitting, reg...\n",
       "5            [deep, network, overfitting, optimization, ]\n",
       "6             [deep, network, overfitting, performance, ]\n",
       "7                                      [hidden, layers, ]\n",
       "8                       [deep, network, generalization, ]\n",
       "9                       [deep, network, hidden, layers, ]\n",
       "10                           [models, problem, solving, ]\n",
       "11      [neural, networks, machine, learning, deep, ne...\n",
       "12      [deep, learning, unsupervised, learning, trans...\n",
       "13      [convolutional, neural, networks, image, recog...\n",
       "14      [neural, networks, feedforward, neural, networ...\n",
       "15      [philosophy, ethics, autonomous, vehicles, dec...\n",
       "16      [deep, network, algorithm, autonomous, vehicle...\n",
       "17                     [comparison, boltzmann, machine, ]\n",
       "18      [evolutionary, algorithms, topology, efficienc...\n",
       "19         [convolutional, neural, networks, deepdream, ]\n",
       "20          [performance, neural, doodle, deepdreaming, ]\n",
       "21                             [neural, networks, math, ]\n",
       "22      [convolutional, neural, networks, deepdreaming, ]\n",
       "23      [convolutional, neural, networks, deepdream, c...\n",
       "24      [quantum, computing, handwritten, characters, ...\n",
       "25                [emotional, intelligence, chat, bots, ]\n",
       "26                          [algorithm, deep, learning, ]\n",
       "27                                            [storage, ]\n",
       "28              [natural, language, processing, watson, ]\n",
       "29      [algorithm, models, research, storage, lexical...\n",
       "                              ...                        \n",
       "5731                         [backpropagation, weights, ]\n",
       "5732                           [prediction, regression, ]\n",
       "5733    [recurrent, neural, networks, long, short, ter...\n",
       "5734    [neural, networks, deep, learning, training, s...\n",
       "5735                                  [tensorflow, c++, ]\n",
       "5736                       [neural, networks, training, ]\n",
       "5737    [neural, networks, recurrent, neural, networks...\n",
       "5738    [neural, networks, keras, recurrent, neural, n...\n",
       "5739    [neural, networks, machine, learning, theory, ...\n",
       "5740                               [optimization, yolo, ]\n",
       "5741                                [object, detection, ]\n",
       "5742    [reinforcement, learning, game, ai, q, learnin...\n",
       "5743    [machine, learning, deep, learning, comparison...\n",
       "5744    [deep, learning, natural, language, processing...\n",
       "5745    [convolutional, neural, networks, image, recog...\n",
       "5746    [neural, networks, natural, language, processi...\n",
       "5747    [reinforcement, learning, policy, gradients, m...\n",
       "5748                                   [planning, pddl, ]\n",
       "5749    [deep, rl, policy, gradients, function, approx...\n",
       "5750    [machine, learning, backpropagation, papers, r...\n",
       "5751    [machine, learning, deep, learning, keras, mac...\n",
       "5752    [reinforcement, learning, ai, design, q, learn...\n",
       "5753    [reinforcement, learning, ai, design, tensorfl...\n",
       "5754                                           [python, ]\n",
       "5755    [deep, learning, geometric, deep, learning, gr...\n",
       "5756                              [social, computation, ]\n",
       "5757    [deep, learning, time, series, sequence, model...\n",
       "5758    [search, proofs, heuristics, admissible, heuri...\n",
       "5759           [machine, learning, recommender, system, ]\n",
       "5760                                   [deep, learning, ]\n",
       "Name: Tags, Length: 5761, dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newposts['Tags']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8R2-H5o2aJ3r"
   },
   "outputs": [],
   "source": [
    "newposts['Tags'] = newposts['Tags'].apply(lambda x: ' '.join(map(str, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nKY9xEDYr6ma"
   },
   "outputs": [],
   "source": [
    "newposts=newposts[newposts['Tags'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qyb1Z3rqsFDE"
   },
   "outputs": [],
   "source": [
    "newposts = newposts.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0vlAZXjsJwK"
   },
   "outputs": [],
   "source": [
    "del newposts['index']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1ZAJyX_TsfWt"
   },
   "source": [
    "Count vectorizer method applied on tags data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sqvu-Xl_c3_k"
   },
   "outputs": [],
   "source": [
    "def wm2df(wm, feat_names):\n",
    "    \n",
    "    # create an index for each row\n",
    "    doc_names = ['Doc{:d}'.format(idx) for idx, _ in enumerate(wm)]\n",
    "    df = pd.DataFrame(data=wm.toarray(), index=doc_names,\n",
    "                      columns=feat_names)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RrGFXRoPfslX"
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "newposts.to_pickle(\"CQA_FRONTEND/static/data/newposts\") \n",
    "cvec = CountVectorizer()\n",
    "corpus = newposts['Tags'].tolist()\n",
    "tags_vec = cvec.fit_transform(corpus)\n",
    "tokens = cvec.get_feature_names()\n",
    "wm2df(tags_vec, tokens)\n",
    "newposts.insert(4,'TagsVec', tags_vec) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aU2uo04hs7DF"
   },
   "outputs": [],
   "source": [
    "word_df = pd.DataFrame(tags_vec.toarray(),columns=tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QttF1ozor6jB"
   },
   "outputs": [],
   "source": [
    "tags_added=pd.concat([newposts, word_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BPJHn6var-ar"
   },
   "outputs": [],
   "source": [
    "tags_added=tags_added.drop(axis=1,columns=[\"TagsVec\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eAYMIIrMsCfI"
   },
   "outputs": [],
   "source": [
    "tags_added= tags_added.drop(axis = 1, columns = ['Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bk9WhKUFsGrm"
   },
   "outputs": [],
   "source": [
    "tags_added= tags_added.drop(axis = 1, columns = ['New Id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fk3f8VH3ssIt"
   },
   "source": [
    "Demonstration of data frame after tags added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 248
    },
    "colab_type": "code",
    "id": "8aqYWi8qvDIb",
    "outputId": "b800636c-2ae7-498b-c39c-9feb5760a5a0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>Title</th>\n",
       "      <th>Body</th>\n",
       "      <th>ID</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>IsAnswered</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Why gradients are so small in deep learning?</td>\n",
       "      <td>&lt;p&gt;The learning rate in my model is &lt;code&gt;0.00...</td>\n",
       "      <td>18325</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 641 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreationDate_1  CreationDate_2  CreationDate_3  \\\n",
       "5760             0.0             0.0             0.0   \n",
       "\n",
       "                                             Title  \\\n",
       "5760  Why gradients are so small in deep learning?   \n",
       "\n",
       "                                                   Body     ID  Tag Count  \\\n",
       "5760  <p>The learning rate in my model is <code>0.00...  18325          1   \n",
       "\n",
       "      IsAnswered  User DownVotes  User UpVotes  ...  weight  weights  wetware  \\\n",
       "5760           0               0            11  ...       0        0        0   \n",
       "\n",
       "      winter  word  word2vec  words  world  yolo  zero  \n",
       "5760       0     0         0      0      0     0     0  \n",
       "\n",
       "[1 rows x 641 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_added.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l1J2IVu8pUyB"
   },
   "source": [
    "Body(body of question) data is cleaned from xml tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7Ougid2KyRoT"
   },
   "outputs": [],
   "source": [
    "content = []\n",
    "\n",
    "for data in tags_added['Body']:\n",
    "    cleantext = BeautifulSoup(data, \"lxml\").text\n",
    "    content.append(cleantext)\n",
    "tags_added.insert(5,\"Bodynew\", content)\n",
    "tags_added= tags_added.drop(axis = 1, columns = ['Body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "GauoZ_SAxpaY"
   },
   "source": [
    "Content parameter = Title of question + Body of question "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RuLykK_dxkhY"
   },
   "outputs": [],
   "source": [
    "tags_added['Content'] = tags_added[['Title', 'Bodynew']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ePBSMG0kdv2n"
   },
   "outputs": [],
   "source": [
    "tags_added['Content'] = tags_added['Content'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "oWBGdrPHeMg2",
    "outputId": "8156be05-2502-4acb-a781-c11e1fc05da0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [what, is, \"backprop\"?, what, does, \"backprop\"...\n",
       "1       [how, does, noise, affect, generalization?, do...\n",
       "2       [how, to, find, the, optimal, number, of, neur...\n",
       "3       [what, is, fuzzy, logic?, i'm, new, to, a.i., ...\n",
       "4       [what, is, \"early, stopping\", in, machine, lea...\n",
       "5       [what, are, the, methods, of, optimizing, over...\n",
       "6       [what, is, the, \"dropout\", technique?, what, p...\n",
       "7       [what, is, the, purpose, of, the, hidden, laye...\n",
       "8       [how, can, generalization, error, be, estimate...\n",
       "9       [what, kind, of, problems, require, more, than...\n",
       "10      [what, are, the, real, world, uses, for, sat, ...\n",
       "11      [how, is, a, deep, neural, network, different,...\n",
       "12      [why, does, unsupervised, pre-training, help, ...\n",
       "13      [how, is, it, possible, that, deep, neural, ne...\n",
       "14      [what, is, the, significance, of, weights, in,...\n",
       "15      [how, could, self-driving, cars, make, ethical...\n",
       "16      [which, machine, learning, algorithm, is, used...\n",
       "17      [what, are, the, main, differences, between, d...\n",
       "18      [number, of, input, variables, for, a, cellula...\n",
       "19      [can, deepdream, produce, a, \"dream\", from, 3,...\n",
       "20      [why, is, the, generation, of, deep, style, im...\n",
       "21      [is, it, possible, to, train, the, neural, net...\n",
       "22      [is, it, possible, to, apply, deep, dream, tec...\n",
       "23      [why, would, neural, network, dream, scenes, m...\n",
       "24      [what, are, the, challenges, for, recognising,...\n",
       "25      [how, can, you, simulate, level, of, curiosity...\n",
       "26      [how, to, write, c, decompiler, using, ai?, i,...\n",
       "27      [what's, the, most, suitable, format, to, stor...\n",
       "28      [what, are, the, main, ai, technologies, behin...\n",
       "29      [how, to, store, datasets, of, lexical, connec...\n",
       "                              ...                        \n",
       "5731    [function, to, update, weights, in, back-propa...\n",
       "5732    [predicting, population, density, from, satell...\n",
       "5733    [recurrent, neural, network, for, survival, an...\n",
       "5734    [deep, learning, with, kfold, cross, validatio...\n",
       "5735    [how, can, i, install, tensorflow, for, c++, i...\n",
       "5736    [is, this, model, overfitted, or, not?, i, am,...\n",
       "5737    [how, to, pad, sequences, during, training, fo...\n",
       "5738    [my, ctc, loss, model's, loss, stagnates, and,...\n",
       "5739    [is, there, a, way, to, ensure, that, my, mode...\n",
       "5740    [object, detection, and, choice, of, optimizer...\n",
       "5741    [cbir, and, object, detection, how, does, cbir...\n",
       "5742    [is, there, a, tutorial, that, explains, from,...\n",
       "5743    [what, are, the, differences, between, transfe...\n",
       "5744    [why, is, my, loss, (binary, cross, entropy), ...\n",
       "5745    [should, i, apply, image, processing, techniqu...\n",
       "5746    [is, it, possible, to, derive, meaning, from, ...\n",
       "5747    [how, can, i, constraint, the, actions, with, ...\n",
       "5748    [can, two, planning, pddl, actions, be, taken,...\n",
       "5749    [monte, carlo, updates, on, policy, gradient, ...\n",
       "5750    [how, is, the, gradient, with, respect, to, we...\n",
       "5751    [how, can, i, deploy, a, keras, machine, trans...\n",
       "5752    [how, should, i, define, the, state, space, fo...\n",
       "5753    [ai, logistic, center, simulation, first, of, ...\n",
       "5754    [how, to, create, create, and, set, virtual, e...\n",
       "5755    [suitable, deep, learning, algorithms, for, sp...\n",
       "5756    [is, a, dystopian, surveillance, state, comput...\n",
       "5757    [what's, the, best, method, to, predict/genera...\n",
       "5758    [is, the, summation, of, consistent, heuristic...\n",
       "5759    [how, to, model, personalized, threshold, prob...\n",
       "5760    [why, gradients, are, so, small, in, deep, lea...\n",
       "Name: Content, Length: 5761, dtype: object"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags_added['Content']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0CrzUx_FpeH7"
   },
   "source": [
    "Doc2vec method implemented on Content data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K0FHpzC8erkL"
   },
   "outputs": [],
   "source": [
    "# Set file names for train and test data\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "        for i, line in enumerate(fname):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9UjdX8ltLuOo"
   },
   "outputs": [],
   "source": [
    "tags_added = tags_added[tags_added['Content'].notna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Y7sVNN85w1oe"
   },
   "outputs": [],
   "source": [
    "tags_added_fix = tags_added.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OzuWQUNAw9GS"
   },
   "outputs": [],
   "source": [
    "del tags_added_fix['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oMemlxGzeud1"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "vecList = []\n",
    "for index, row in tags_added_fix.iterrows():\n",
    "  train_corpus = list(read_corpus(row['Content']))\n",
    " \n",
    "  model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=1, epochs=30)\n",
    "  model.build_vocab(train_corpus)\n",
    "  model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "  vector = model.infer_vector(row['Content'])\n",
    "  #print(vector)\n",
    "  vecList.append(vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sApaS70pp7eA"
   },
   "source": [
    "Vector size is defined as 100. Each vector has been added to the data frame for corresponding questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V6PcrFXgkZF_"
   },
   "outputs": [],
   "source": [
    "col_list_content = ['content' + str(x) for x in range(0,100)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qKeh92ylSL-X"
   },
   "outputs": [],
   "source": [
    "doc2vecdf = pd.DataFrame(vecList,columns=col_list_content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A8exu6VxlXGC"
   },
   "outputs": [],
   "source": [
    "final_train=pd.concat([tags_added_fix, doc2vecdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w6sOdPSgCrzm"
   },
   "outputs": [],
   "source": [
    "final_train.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "duOc7CR-rCMz"
   },
   "source": [
    "To make a better prediction data is shuffled \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wUrpwsKnT2_0"
   },
   "outputs": [],
   "source": [
    "shuffled_final=final_train.sample(frac=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-Dt2KFI_Usfn"
   },
   "outputs": [],
   "source": [
    "shuffled_final = shuffled_final.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8x9xh8PHNr-F"
   },
   "outputs": [],
   "source": [
    "shuffled_final=shuffled_final.drop(axis=1, columns=[\"index\",\"ID\",\"Content\",\"Bodynew\",\"Title\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "euBYLBwTQ8gX"
   },
   "outputs": [],
   "source": [
    "shuffled_final=shuffled_final.fillna(0.0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fX-7yAtj5wTc"
   },
   "outputs": [],
   "source": [
    "shuffled_final.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 456
    },
    "colab_type": "code",
    "id": "TZZouPFAXodN",
    "outputId": "ff27dc09-aab5-4467-bbfa-fc78f9e61dc0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>IsAnswered</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User Views</th>\n",
       "      <th>UserCreationDate_1</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>29</td>\n",
       "      <td>5607</td>\n",
       "      <td>3179</td>\n",
       "      <td>827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>159</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>247</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>787</td>\n",
       "      <td>204</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>283</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>145</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>299</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>189</td>\n",
       "      <td>13</td>\n",
       "      <td>55</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>173</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2524</td>\n",
       "      <td>177</td>\n",
       "      <td>806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>509</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>209</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>749</td>\n",
       "      <td>18</td>\n",
       "      <td>116</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>85</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5731</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5732</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1191</td>\n",
       "      <td>39</td>\n",
       "      <td>9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5733</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>445</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5734</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5735</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5736</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>119</td>\n",
       "      <td>2524</td>\n",
       "      <td>177</td>\n",
       "      <td>806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5737</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>268</td>\n",
       "      <td>13</td>\n",
       "      <td>6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5738</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>111</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>331</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5740</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5741</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>123</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5743</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5744</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5745</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>101</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5746</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>334</td>\n",
       "      <td>6</td>\n",
       "      <td>28</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5747</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>29</td>\n",
       "      <td>5607</td>\n",
       "      <td>3179</td>\n",
       "      <td>827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5748</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>221</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5749</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>293</td>\n",
       "      <td>5</td>\n",
       "      <td>17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5750</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>181</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5751</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5752</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5754</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5755</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5756</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5757</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>567</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5758</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5759</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>73</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5761 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      CreationDate_1  CreationDate_2  CreationDate_3  IsAnswered  Tag Count  \\\n",
       "0                0.0             0.0             0.0           1          2   \n",
       "1                0.0             1.0             0.0           1          1   \n",
       "2                0.0             1.0             0.0           0          1   \n",
       "3                1.0             0.0             0.0           1          4   \n",
       "4                0.0             0.0             1.0           1          3   \n",
       "5                0.0             0.0             0.0           1          4   \n",
       "6                0.0             1.0             0.0           1          4   \n",
       "7                0.0             0.0             0.0           1          2   \n",
       "8                0.0             0.0             1.0           1          1   \n",
       "9                0.0             1.0             0.0           1          1   \n",
       "10               1.0             0.0             0.0           0          2   \n",
       "11               1.0             0.0             0.0           1          4   \n",
       "12               0.0             0.0             0.0           0          3   \n",
       "13               0.0             1.0             0.0           1          3   \n",
       "14               1.0             0.0             0.0           0          2   \n",
       "15               0.0             0.0             1.0           0          1   \n",
       "16               0.0             0.0             0.0           0          2   \n",
       "17               1.0             0.0             0.0           1          5   \n",
       "18               0.0             1.0             0.0           1          4   \n",
       "19               1.0             0.0             0.0           1          4   \n",
       "20               0.0             0.0             0.0           0          1   \n",
       "21               0.0             0.0             1.0           1          3   \n",
       "22               0.0             0.0             0.0           1          4   \n",
       "23               0.0             0.0             1.0           1          3   \n",
       "24               0.0             1.0             0.0           1          2   \n",
       "25               0.0             0.0             0.0           0          2   \n",
       "26               0.0             1.0             0.0           0          5   \n",
       "27               1.0             0.0             0.0           0          2   \n",
       "28               0.0             1.0             0.0           1          4   \n",
       "29               0.0             0.0             1.0           0          5   \n",
       "...              ...             ...             ...         ...        ...   \n",
       "5731             0.0             1.0             0.0           1          3   \n",
       "5732             0.0             1.0             0.0           1          2   \n",
       "5733             0.0             1.0             0.0           1          3   \n",
       "5734             0.0             0.0             0.0           0          4   \n",
       "5735             1.0             0.0             0.0           1          2   \n",
       "5736             0.0             1.0             0.0           1          1   \n",
       "5737             1.0             0.0             0.0           0          1   \n",
       "5738             0.0             0.0             0.0           1          3   \n",
       "5739             0.0             0.0             0.0           1          2   \n",
       "5740             1.0             0.0             0.0           1          3   \n",
       "5741             0.0             1.0             0.0           1          1   \n",
       "5742             1.0             0.0             0.0           0          5   \n",
       "5743             0.0             1.0             0.0           1          2   \n",
       "5744             0.0             1.0             0.0           0          2   \n",
       "5745             0.0             0.0             0.0           1          3   \n",
       "5746             0.0             0.0             1.0           0          2   \n",
       "5747             0.0             1.0             0.0           1          5   \n",
       "5748             0.0             1.0             0.0           0          2   \n",
       "5749             1.0             0.0             0.0           1          3   \n",
       "5750             1.0             0.0             0.0           1          3   \n",
       "5751             0.0             0.0             1.0           1          2   \n",
       "5752             0.0             1.0             0.0           0          3   \n",
       "5753             0.0             0.0             0.0           1          2   \n",
       "5754             1.0             0.0             0.0           1          4   \n",
       "5755             0.0             0.0             0.0           1          5   \n",
       "5756             0.0             0.0             0.0           0          2   \n",
       "5757             1.0             0.0             0.0           1          2   \n",
       "5758             1.0             0.0             0.0           1          5   \n",
       "5759             0.0             1.0             0.0           1          3   \n",
       "5760             0.0             1.0             0.0           1          5   \n",
       "\n",
       "      User DownVotes  User Reputation  User UpVotes  User Views  \\\n",
       "0                  0               43             1           7   \n",
       "1                 29             5607          3179         827   \n",
       "2                  0               21             0           1   \n",
       "3                  0               41             0           1   \n",
       "4                  0              159             1           1   \n",
       "5                  0               99             0           3   \n",
       "6                  0              111             2           0   \n",
       "7                  0              247             0           3   \n",
       "8                 10              787           204           8   \n",
       "9                  0               43             0           1   \n",
       "10                 0              283             6           7   \n",
       "11                 0              145             2           7   \n",
       "12                 0              299             5           3   \n",
       "13                 0              101             0           1   \n",
       "14                 0               65             1           2   \n",
       "15                 0               21             0           1   \n",
       "16                 0              189            13          55   \n",
       "17                 0              173             7          31   \n",
       "18                 0               83             3           3   \n",
       "19                 0               13             0           5   \n",
       "20               119             2524           177         806   \n",
       "21                 0              191             4           8   \n",
       "22                 0               23             0           0   \n",
       "23                 0               41             0           5   \n",
       "24                 0              509            17          35   \n",
       "25                 0              209             0          12   \n",
       "26                 0              749            18         116   \n",
       "27                 0              147             1           3   \n",
       "28                 0               85             6          18   \n",
       "29                 0              101             0           0   \n",
       "...              ...              ...           ...         ...   \n",
       "5731               0              109             0           3   \n",
       "5732               5             1191            39           9   \n",
       "5733               0              445            14          50   \n",
       "5734               0              155             5           2   \n",
       "5735               0              141             1           1   \n",
       "5736             119             2524           177         806   \n",
       "5737               0              268            13           6   \n",
       "5738               0              111             1           2   \n",
       "5739               1              331             0          12   \n",
       "5740               0               11             0           0   \n",
       "5741               0              123             2           1   \n",
       "5742               0               93             1           7   \n",
       "5743               0              221             2           1   \n",
       "5744               0               11             0           1   \n",
       "5745               0              101             0           0   \n",
       "5746               1              334             6          28   \n",
       "5747              29             5607          3179         827   \n",
       "5748               0              221             2           1   \n",
       "5749               0              293             5          17   \n",
       "5750               0              181             2           3   \n",
       "5751               0               23             1           2   \n",
       "5752               0               11             0           0   \n",
       "5753               0               25             1           1   \n",
       "5754               0              141             0           1   \n",
       "5755               0              163             2           4   \n",
       "5756               0               21             0           1   \n",
       "5757               0              567            12          16   \n",
       "5758               0               41             0           3   \n",
       "5759               0               21             0           1   \n",
       "5760               0               73             1           2   \n",
       "\n",
       "      UserCreationDate_1  ...  weight  weights  wetware  winter  word  \\\n",
       "0                    0.0  ...       0        0        0       0     0   \n",
       "1                    0.0  ...       0        0        0       0     0   \n",
       "2                    0.0  ...       0        0        0       0     0   \n",
       "3                    1.0  ...       0        0        0       0     0   \n",
       "4                    1.0  ...       0        0        0       0     0   \n",
       "5                    0.0  ...       0        0        0       0     0   \n",
       "6                    0.0  ...       0        0        0       0     0   \n",
       "7                    0.0  ...       0        0        0       0     0   \n",
       "8                    0.0  ...       0        0        0       0     0   \n",
       "9                    0.0  ...       0        0        0       0     0   \n",
       "10                   0.0  ...       0        0        0       0     0   \n",
       "11                   0.0  ...       0        0        0       0     0   \n",
       "12                   0.0  ...       0        0        0       0     0   \n",
       "13                   0.0  ...       0        0        0       0     0   \n",
       "14                   0.0  ...       0        0        0       0     0   \n",
       "15                   0.0  ...       0        0        0       0     0   \n",
       "16                   1.0  ...       0        0        0       0     0   \n",
       "17                   1.0  ...       0        0        0       0     0   \n",
       "18                   0.0  ...       0        0        0       0     0   \n",
       "19                   1.0  ...       0        0        0       0     0   \n",
       "20                   1.0  ...       0        0        0       0     0   \n",
       "21                   0.0  ...       0        0        0       0     0   \n",
       "22                   0.0  ...       0        0        0       0     0   \n",
       "23                   0.0  ...       0        0        0       0     0   \n",
       "24                   1.0  ...       0        0        0       0     0   \n",
       "25                   0.0  ...       0        0        0       0     0   \n",
       "26                   0.0  ...       0        0        0       0     0   \n",
       "27                   0.0  ...       0        0        0       0     0   \n",
       "28                   1.0  ...       0        0        0       0     0   \n",
       "29                   0.0  ...       0        0        0       0     0   \n",
       "...                  ...  ...     ...      ...      ...     ...   ...   \n",
       "5731                 0.0  ...       0        0        0       0     0   \n",
       "5732                 1.0  ...       0        0        0       0     0   \n",
       "5733                 1.0  ...       0        0        0       0     0   \n",
       "5734                 0.0  ...       0        0        0       0     0   \n",
       "5735                 1.0  ...       0        0        0       0     0   \n",
       "5736                 1.0  ...       0        0        0       0     0   \n",
       "5737                 1.0  ...       0        0        0       0     0   \n",
       "5738                 0.0  ...       0        0        0       0     0   \n",
       "5739                 0.0  ...       0        0        0       0     0   \n",
       "5740                 1.0  ...       0        0        0       0     0   \n",
       "5741                 1.0  ...       0        0        0       0     0   \n",
       "5742                 0.0  ...       0        0        0       0     0   \n",
       "5743                 0.0  ...       0        0        0       0     0   \n",
       "5744                 0.0  ...       0        0        0       0     0   \n",
       "5745                 0.0  ...       0        0        0       0     0   \n",
       "5746                 0.0  ...       0        0        0       0     0   \n",
       "5747                 0.0  ...       0        0        0       0     0   \n",
       "5748                 0.0  ...       0        0        0       0     0   \n",
       "5749                 0.0  ...       0        0        0       0     0   \n",
       "5750                 0.0  ...       0        0        0       0     0   \n",
       "5751                 0.0  ...       0        0        0       0     0   \n",
       "5752                 0.0  ...       0        0        0       0     0   \n",
       "5753                 0.0  ...       0        0        0       0     0   \n",
       "5754                 1.0  ...       0        0        0       0     0   \n",
       "5755                 0.0  ...       0        0        0       0     0   \n",
       "5756                 0.0  ...       0        0        0       0     0   \n",
       "5757                 0.0  ...       0        0        0       0     0   \n",
       "5758                 1.0  ...       0        0        0       0     0   \n",
       "5759                 0.0  ...       0        0        0       0     0   \n",
       "5760                 0.0  ...       0        0        0       0     0   \n",
       "\n",
       "      word2vec  words  world  yolo  zero  \n",
       "0            0      0      0     0     0  \n",
       "1            0      0      0     0     0  \n",
       "2            0      0      0     0     0  \n",
       "3            0      0      0     0     0  \n",
       "4            0      0      0     0     0  \n",
       "5            0      0      0     0     0  \n",
       "6            0      0      0     0     0  \n",
       "7            0      0      0     0     0  \n",
       "8            0      0      0     0     0  \n",
       "9            0      0      0     0     0  \n",
       "10           0      0      0     0     0  \n",
       "11           0      0      0     0     0  \n",
       "12           0      0      0     0     0  \n",
       "13           0      0      0     0     0  \n",
       "14           0      0      0     0     0  \n",
       "15           0      0      0     0     0  \n",
       "16           0      0      0     0     0  \n",
       "17           0      0      0     0     0  \n",
       "18           0      0      0     0     0  \n",
       "19           0      0      0     0     0  \n",
       "20           0      0      0     0     0  \n",
       "21           0      0      0     0     0  \n",
       "22           0      0      0     0     0  \n",
       "23           0      0      0     0     0  \n",
       "24           0      0      0     0     0  \n",
       "25           0      0      0     0     0  \n",
       "26           0      0      0     0     0  \n",
       "27           0      0      0     0     0  \n",
       "28           0      0      0     0     0  \n",
       "29           0      0      0     0     0  \n",
       "...        ...    ...    ...   ...   ...  \n",
       "5731         0      0      0     0     0  \n",
       "5732         0      0      0     0     0  \n",
       "5733         0      0      0     0     0  \n",
       "5734         0      0      0     0     0  \n",
       "5735         0      0      0     0     0  \n",
       "5736         0      0      0     0     0  \n",
       "5737         0      0      0     0     0  \n",
       "5738         0      0      0     0     0  \n",
       "5739         0      0      0     0     0  \n",
       "5740         0      0      0     0     0  \n",
       "5741         0      0      0     0     0  \n",
       "5742         0      0      0     0     0  \n",
       "5743         0      0      0     0     0  \n",
       "5744         0      0      0     0     0  \n",
       "5745         0      0      0     0     0  \n",
       "5746         0      0      0     0     0  \n",
       "5747         0      0      0     0     0  \n",
       "5748         0      0      0     0     0  \n",
       "5749         0      0      0     0     0  \n",
       "5750         0      0      0     0     0  \n",
       "5751         0      0      0     0     0  \n",
       "5752         0      0      0     0     0  \n",
       "5753         0      0      0     0     0  \n",
       "5754         0      0      0     0     0  \n",
       "5755         0      0      0     0     1  \n",
       "5756         0      0      0     0     0  \n",
       "5757         0      0      0     0     0  \n",
       "5758         0      0      0     0     0  \n",
       "5759         0      0      0     0     0  \n",
       "5760         0      0      0     0     0  \n",
       "\n",
       "[5761 rows x 738 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_final.replace(-9223372036854775808,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "byFUeePIt7si"
   },
   "source": [
    "  This is where we define the test set, for the user interface it will be dynamic parameter and updated for each question will be asked , however at this stage we have define the question manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 114
    },
    "colab_type": "code",
    "id": "XeSGRqnJSLYj",
    "outputId": "7fc2dc78-ebe3-4e51-948b-074e4d80c07e"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Tags</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User Creation Date</th>\n",
       "      <th>User Last Access Date</th>\n",
       "      <th>User Views</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User DownVotes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As far I know, the RNN accepts a sequence as i...</td>\n",
       "      <td>Are there neural networks that accept graphs o...</td>\n",
       "      <td>2016-08-02T15:41:22.020</td>\n",
       "      <td>&lt;neural-networks&gt;&lt;graphs&gt;</td>\n",
       "      <td>344</td>\n",
       "      <td>2016-08-02T15:38:36.723</td>\n",
       "      <td>2019-11-30T19:21:45.687</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  As far I know, the RNN accepts a sequence as i...   \n",
       "\n",
       "                                               Title            Creation Date  \\\n",
       "0  Are there neural networks that accept graphs o...  2016-08-02T15:41:22.020   \n",
       "\n",
       "                        Tags User Reputation       User Creation Date  \\\n",
       "0  <neural-networks><graphs>             344  2016-08-02T15:38:36.723   \n",
       "\n",
       "     User Last Access Date User Views User UpVotes User DownVotes  \n",
       "0  2019-11-30T19:21:45.687         30            0              0  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "derived_question_body =\"As far I know, the RNN accepts a sequence as input and can produce as a sequence as output.Are there neural networks that accept graphs or trees as inputs, so that to represent the relationships between the nodes of the graph or tree?\"\n",
    "derived_title=\"Are there neural networks that accept graphs or trees as inputs?\"\n",
    "derived_creation_date=\"2016-08-02T15:41:22.020\"\n",
    "derived_tags=\"<neural-networks><graphs>\"\n",
    "derived_userReputation=\"344\"\n",
    "derived_userCreationDate=\"2016-08-02T15:38:36.723\"\n",
    "derived_userLastAccessDate=\"2019-11-30T19:21:45.687\"\n",
    "derived_userViews=\"30\" \n",
    "derived_userUpVotes=\"0\" \n",
    "derived_userDownVotes=\"0\"\n",
    "# create a new data frame \n",
    "\n",
    "df = pd.DataFrame({'Question': [derived_question_body],'Title' :[derived_title],'Creation Date':[derived_creation_date],'Tags':[derived_tags],'User Reputation': [derived_userReputation],\"User Creation Date\" : [derived_userCreationDate],\"User Last Access Date\" : [derived_userLastAccessDate],\"User Views\": [derived_userViews],\"User UpVotes\": [derived_userUpVotes],\"User DownVotes\": [derived_userDownVotes]}) \n",
    "   \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZlVsA_VBuSo8"
   },
   "source": [
    "Same preprocessing applied on Date format data \n",
    "\n",
    "*   Label encoding\n",
    "*   One hot encoding\n",
    "\n",
    "Since there is only 1 question on test set that means there will be only 1 part of the day to encode . So one-hot-encoding would not be able to create columns for each part of the day . We have written a function to convert label encoded parameter to one hot encoded parameters.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "efXXCyOGeeXE"
   },
   "outputs": [],
   "source": [
    "df['Creation Date'] = pd.to_datetime(df['Creation Date'])\n",
    "df['User Creation Date'] = pd.to_datetime(df['User Creation Date'])\n",
    "df['User Last Access Date'] = pd.to_datetime(df['User Last Access Date'])\n",
    "df['User DownVotes'] = df['User DownVotes'].astype(int)\n",
    "df['User UpVotes'] = df['User UpVotes'].astype(int)\n",
    "df['User Reputation'] = df['User Reputation'].astype(int)\n",
    "df['User Views'] = df['User Views'].astype(int)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "U7yUB-q7eefM"
   },
   "outputs": [],
   "source": [
    "df= df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xH7GNiN8vAI1"
   },
   "source": [
    "Label encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d7ga_OYHeeip"
   },
   "outputs": [],
   "source": [
    "def get_part_of_day(x):\n",
    "    return (\n",
    "        \"1\" if 5 <= int(x.strftime('%H')) <= 10\n",
    "        else\n",
    "        \"2\" if 11<=  int(x.strftime('%H'))<= 16\n",
    "        else\n",
    "        \"3\" if 17 <= int(x.strftime('%H'))  <= 22\n",
    "        else\n",
    "        \"4\"\n",
    "    )\n",
    "    \n",
    "df[\"Creation Date\"] = df[\"Creation Date\"].apply(get_part_of_day)\n",
    "df[\"User Creation Date\"] = df[\"User Creation Date\"].apply(get_part_of_day)\n",
    "df[\"User Last Access Date\"] = df[\"User Last Access Date\"].apply(get_part_of_day)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "upw_co8vvCtR"
   },
   "source": [
    "One hot encoding function for the date format data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JZ1phHD56ulc"
   },
   "outputs": [],
   "source": [
    "def encoder(x):\n",
    "  a = 0.0\n",
    "  b = 0.0\n",
    "  c = 0.0\n",
    "\n",
    "  if(x == \"1\"):\n",
    "    return a,b,c\n",
    "  elif (x == \"2\"):\n",
    "    a = 1.0\n",
    "    return a,b,c\n",
    "  elif (x == \"3\"):\n",
    "    b = 1.0\n",
    "    return a,b,c\n",
    "  else:\n",
    "    c = 1.0\n",
    "    return a,b,c\n",
    "\n",
    "df[\"CreationDate_1\"], df[\"CreationDate_2\"], df[\"CreationDate_3\"] = zip(*df['Creation Date'].map(encoder))\n",
    "df[\"UserCreationDate_1\"], df[\"UserCreationDate_2\"], df[\"UserCreationDate_3\"] = zip(*df['User Creation Date'].map(encoder))\n",
    "df[\"UserLastAccessDate_1\"], df[\"UserLastAccessDate_2\"], df[\"UserLastAccessDate_3\"] = zip(*df['User Last Access Date'].map(encoder))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ijVwhSKPvHX7"
   },
   "source": [
    "Tag count calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WY4R4ZC25kdS"
   },
   "outputs": [],
   "source": [
    "df['Tag Count'] = df['Tags'].str.count('<')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Rrx0p7HvK-f"
   },
   "source": [
    "Tags data is cleaned from xml format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YmVxo0BlNfo-"
   },
   "outputs": [],
   "source": [
    "df['Tags'] = df['Tags'].str.replace('<', '')\n",
    "df['Tags'] = df['Tags'].str.replace('>', ' ')\n",
    "df['Tags'] = df['Tags'].str.replace('-', ' ')\n",
    "df['Tags'] = df['Tags'].str.split(' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2CLHhbecvVmG"
   },
   "source": [
    "To create same data frame for the test data , we have used the tokens that we created from train set's tags data. Updated dataframe according to the existence of tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZEuoCBt7AC5"
   },
   "outputs": [],
   "source": [
    "alltags = pd.DataFrame(0, index=np.arange(1), columns=tokens)\n",
    "for tag in df.iloc[0]['Tags']:\n",
    "  alltags[tag] = 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3-aXaoYh7FjK"
   },
   "outputs": [],
   "source": [
    "alltags\n",
    "q_tags_added=pd.concat([df, alltags], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hvNePRsm7Juw"
   },
   "outputs": [],
   "source": [
    "q_tags_added = q_tags_added.iloc[:, :-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KMt0O5u3v7_N"
   },
   "source": [
    "Data frame after tags are added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "colab_type": "code",
    "id": "THOLolgd7Kgk",
    "outputId": "d505b040-3094-4ce3-9a95-9560fb14394b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Question</th>\n",
       "      <th>Title</th>\n",
       "      <th>Creation Date</th>\n",
       "      <th>Tags</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User Creation Date</th>\n",
       "      <th>User Last Access Date</th>\n",
       "      <th>User Views</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>As far I know, the RNN accepts a sequence as i...</td>\n",
       "      <td>Are there neural networks that accept graphs o...</td>\n",
       "      <td>2</td>\n",
       "      <td>[neural, networks, graphs, ]</td>\n",
       "      <td>344</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 643 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Question  \\\n",
       "0  As far I know, the RNN accepts a sequence as i...   \n",
       "\n",
       "                                               Title Creation Date  \\\n",
       "0  Are there neural networks that accept graphs o...             2   \n",
       "\n",
       "                           Tags  User Reputation User Creation Date  \\\n",
       "0  [neural, networks, graphs, ]              344                  2   \n",
       "\n",
       "  User Last Access Date  User Views  User UpVotes  User DownVotes  ...  \\\n",
       "0                     3          30             0               0  ...   \n",
       "\n",
       "   weight  weights  wetware  winter  word  word2vec  words  world  yolo  zero  \n",
       "0       0        0        0       0     0         0      0      0     0     0  \n",
       "\n",
       "[1 rows x 643 columns]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_tags_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BGxKa-Y4wEfp"
   },
   "source": [
    "Doc2vec method implemented in same manner as train set\n",
    "body and title of the question used together to create vectoral representation of question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RJFSFtel7UXH"
   },
   "outputs": [],
   "source": [
    "#words kolonu title ile bodynin birleşmiş hali, \n",
    "q_tags_added['Content'] = q_tags_added[['Title', 'Question']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LBnlxZyKdlMm"
   },
   "outputs": [],
   "source": [
    "q_tags_added['Content'] = q_tags_added['Content'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uT48iRXIddAY"
   },
   "outputs": [],
   "source": [
    "# Set file names for train and test data\n",
    "\n",
    "def read_corpus(fname, tokens_only=False):\n",
    "        for i, line in enumerate(fname):\n",
    "            tokens = gensim.utils.simple_preprocess(line)\n",
    "            if tokens_only:\n",
    "                yield tokens\n",
    "            else:\n",
    "                # For training data, add tags\n",
    "                yield gensim.models.doc2vec.TaggedDocument(tokens, [i])\n",
    "                import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDD5VqFxeKC7"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# choose question posts and take body and convert list and with the help of corpus function each question will be presented as documents.\n",
    "\n",
    "#test_corpus = list(read_corpus(b[b[\"PostTypeId\"]==1][\"Body\"], tokens_only=True))\n",
    "q_vecList = []\n",
    "for index, row in q_tags_added.iterrows():\n",
    "\n",
    "  train_corpus = list(read_corpus(row['Content']))\n",
    "  model = gensim.models.doc2vec.Doc2Vec(vector_size=100, min_count=1, epochs=30)\n",
    "  model.build_vocab(train_corpus)\n",
    "  model.train(train_corpus, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "  vector = model.infer_vector(row['Content'])\n",
    "  #print(vector)\n",
    "  q_vecList.append(vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PpWvuo0peM9i"
   },
   "outputs": [],
   "source": [
    "q_col_list = ['content' + str(x) for x in range(0,100)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "M39IwLVK7ihJ"
   },
   "outputs": [],
   "source": [
    "q_doc2vecdf = pd.DataFrame(q_vecList,columns=q_col_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cPv7AEIf7kG8"
   },
   "outputs": [],
   "source": [
    "final_test=pd.concat([q_tags_added, q_doc2vecdf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "S64kfWWq7mVy"
   },
   "outputs": [],
   "source": [
    "final_test=final_test.drop(axis=1,columns=[\"Content\",\"Question\",\"Title\",\"Creation Date\",\"Tags\",\"User Creation Date\",\"User Last Access Date\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VyfoDqcFe2IQ"
   },
   "outputs": [],
   "source": [
    "final_test=final_test.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RZVPY0C6e5eC"
   },
   "outputs": [],
   "source": [
    "del final_test['index']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aCbDbtA07y6j"
   },
   "outputs": [],
   "source": [
    "final_test=final_test.replace(-9223372036854775808,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s3cm-XE470sj"
   },
   "outputs": [],
   "source": [
    "final_test.sort_index(axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tImS8mUawV0g"
   },
   "source": [
    "For each question their corresponding 100 columns vector representation added to dataframe . This is final version of test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "Y3rw7m_o72ry",
    "outputId": "0005d46b-dcb5-4ff5-e204-e92322a1ae3a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User Views</th>\n",
       "      <th>UserCreationDate_1</th>\n",
       "      <th>UserCreationDate_2</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>344</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreationDate_1  CreationDate_2  CreationDate_3  Tag Count  User DownVotes  \\\n",
       "0             1.0             0.0             0.0          2               0   \n",
       "\n",
       "   User Reputation  User UpVotes  User Views  UserCreationDate_1  \\\n",
       "0              344             0          30                 1.0   \n",
       "\n",
       "   UserCreationDate_2  ...  weight  weights  wetware  winter  word  word2vec  \\\n",
       "0                 0.0  ...       0        0        0       0     0         0   \n",
       "\n",
       "   words  world  yolo  zero  \n",
       "0      0      0     0     0  \n",
       "\n",
       "[1 rows x 737 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 146
    },
    "colab_type": "code",
    "id": "v5FOvTIG85sR",
    "outputId": "2beef800-f2a7-469f-8596-8d0b0a95e8f2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>IsAnswered</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User Views</th>\n",
       "      <th>UserCreationDate_1</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 738 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   CreationDate_1  CreationDate_2  CreationDate_3  IsAnswered  Tag Count  \\\n",
       "0             0.0             0.0             0.0           1          2   \n",
       "\n",
       "   User DownVotes  User Reputation  User UpVotes  User Views  \\\n",
       "0               0               43             1           7   \n",
       "\n",
       "   UserCreationDate_1  ...  weight  weights  wetware  winter  word  word2vec  \\\n",
       "0                 0.0  ...       0        0        0       0     0         0   \n",
       "\n",
       "   words  world  yolo  zero  \n",
       "0      0      0     0     0  \n",
       "\n",
       "[1 rows x 738 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_final.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_7rALoEWw6Yu"
   },
   "source": [
    "There are total 5046 questions when we merged user.xml data and posts.xml data . 3811 of them is answered ,1235 of them is not answered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 208
    },
    "colab_type": "code",
    "id": "sGUsFrJqkzDK",
    "outputId": "f9fcf394-cdc5-40b5-a05d-57ec18a41ba5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreationDate_1</th>\n",
       "      <th>CreationDate_2</th>\n",
       "      <th>CreationDate_3</th>\n",
       "      <th>Tag Count</th>\n",
       "      <th>User DownVotes</th>\n",
       "      <th>User Reputation</th>\n",
       "      <th>User UpVotes</th>\n",
       "      <th>User Views</th>\n",
       "      <th>UserCreationDate_1</th>\n",
       "      <th>UserCreationDate_2</th>\n",
       "      <th>...</th>\n",
       "      <th>weight</th>\n",
       "      <th>weights</th>\n",
       "      <th>wetware</th>\n",
       "      <th>winter</th>\n",
       "      <th>word</th>\n",
       "      <th>word2vec</th>\n",
       "      <th>words</th>\n",
       "      <th>world</th>\n",
       "      <th>yolo</th>\n",
       "      <th>zero</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsAnswered</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>...</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "      <td>1565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>...</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "      <td>4196</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 737 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            CreationDate_1  CreationDate_2  CreationDate_3  Tag Count  \\\n",
       "IsAnswered                                                              \n",
       "0                     1565            1565            1565       1565   \n",
       "1                     4196            4196            4196       4196   \n",
       "\n",
       "            User DownVotes  User Reputation  User UpVotes  User Views  \\\n",
       "IsAnswered                                                              \n",
       "0                     1565             1565          1565        1565   \n",
       "1                     4196             4196          4196        4196   \n",
       "\n",
       "            UserCreationDate_1  UserCreationDate_2  ...  weight  weights  \\\n",
       "IsAnswered                                          ...                    \n",
       "0                         1565                1565  ...    1565     1565   \n",
       "1                         4196                4196  ...    4196     4196   \n",
       "\n",
       "            wetware  winter  word  word2vec  words  world  yolo  zero  \n",
       "IsAnswered                                                             \n",
       "0              1565    1565  1565      1565   1565   1565  1565  1565  \n",
       "1              4196    4196  4196      4196   4196   4196  4196  4196  \n",
       "\n",
       "[2 rows x 737 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shuffled_final.groupby(\"IsAnswered\").count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_final.to_pickle(\"CQA_FRONTEND/static/data/shuffled_perc\")  # where to save it, usually as a .pkl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ouLqRCDehu19"
   },
   "outputs": [],
   "source": [
    "xtrain = shuffled_final.drop(axis = 1, columns=['IsAnswered'])\n",
    "labels = shuffled_final['IsAnswered']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3CJzcUvlxuXr"
   },
   "source": [
    "For the question that has been used as test question: The model predicted that, the question will be answered with 83% probability. This is the final model result for the user interface implementation. Different models have been tried and results of them has shown in the report. This model worked with ≈ 80% accuracy when the data is divided into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "NYLn5Zhil8cE",
    "outputId": "a8b60a25-933e-40a9-b304-ef6d6232d610"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Predicted=[0.25950955 0.74049045]\n"
     ]
    }
   ],
   "source": [
    "# fit final model\n",
    "rfm=RandomForestClassifier(bootstrap = True,n_estimators=100,min_samples_leaf=1,\n",
    "                           random_state=50, max_depth= 50,min_samples_split= 20)\n",
    "\n",
    "rfm.fit(xtrain,labels)\n",
    "\n",
    "ynew = rfm.predict_proba(final_test)\n",
    "# show the inputs and predicted outputs\n",
    "for i in range(len(final_test)):\n",
    "\tprint(\" Predicted=%s\" % (ynew[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rg9DJK2kIjuk"
   },
   "source": [
    "The printed results show that\n",
    "\n",
    "* The question is predicted to be answered with ≈ 81% probability\n",
    "* The question is predicted to be not answered with ≈ 19% probability"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Task1_will_my_question_get_answered.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
